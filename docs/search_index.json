[["index.html", "Digital Humanities in Middle Eastern Studies Syllabus Course Details 0.1 Aims, contents and method of the course 0.2 Course Evaluation 0.3 Class Participation 0.4 Homework 0.5 Final Project 0.6 Study materials: 0.7 Software, Tools, &amp; Technologies: 0.8 Submitting Homework: 0.9 Schedule 0.10 Lesson Topics (subject to modification)", " Digital Humanities in Middle Eastern Studies Maxim G. Romanov 2022-01-08 Syllabus Course Details Course: 57-525 S: Digital Humanities in Middle East Studies — Introduction to Algorithmic Analysis (WS2021) Language of instruction: English Meeting time: Mo 12:00-14:00 Meeting place: due to COVID, all meetings will be held online via Zoom Meeting link: shared via Slack; other details are available via STiNE Office hours: Mo 14:00-15:00 (on Zoom); if you have any questions, please, post them on Slack Instructor: Dr. Maxim Romanov, maxim.romanov@uni-hamburg.de Course: 070172-1 UE Methodological course - Introduction to DH: Tools &amp; Techniques (2020W) Memex Edition Instructor: Dr. Maxim Romanov, maxim.romanov@univie.ac.at 0.1 Aims, contents and method of the course The course is a practical introduction to a series of digital tools and techniques that are relevant for analytical work both inside and outside of academia. The course will cover such topics as sustainable academic/analytical writing, organization of research workflow, data collection and structuring, as well as basics of text analysis, mapping, and social network analysis. In the course of these units, you will start working with Python, one of the most prominent programming languages used now by humanists and data scientists alike (no prior programming experience is required, but beneficial). The assessment will be based on your in-class participation, timely submission of homework assignments, and the final project, where you will be encouraged to work with data from your disciplinary domain. Personal computers are required both for in-class work and for your homework (running full versions of either Windows, MacOS, or Linux; unfortunately, neither tablets nor Chrome-based laptops are suitable for this course). 0.2 Course Evaluation Course evaluation will be a combination of in-class participation (30%), weekly homework assignments (50%), and the final project (20%). 0.3 Class Participation Each class session will consist in large part of practical hands-on exercises led by the instructor. BRING YOUR LAPTOP! We will accommodate whatever operating system you use (Windows, Mac, Linux), but it should be a laptop rather than a tablet. Don’t forget that asking for help counts as participation! 0.4 Homework Just as in research and real life, collaboration is a very good way to learn and is therefore encouraged. If you need help with any assignment, you are welcome to ask a fellow student. If you do work together on homework assignments, then when you submit it please include a brief note (just a sentence or two) to indicate who did what. NB: On submitting homework, see below. 0.5 Final Project Final project will be discussed later. You will have an option to build on what we will be doing in class, but you are most encouraged to pick a topic of your own. The best option will be to work on something relevant to your field of study, your term paper or your thesis. 0.6 Study materials: Most study materials will be distributed by the instructor. * Zelle, John M. 2016. Python Programming: An Introduction to Computer Science. 3rd edition. Portland, Oregon: FRANKLIN BEEDLE &amp; ASSOC. * “Programming Historian” offers a number of tutorials for aspiring digital humanists. These will be assigned to you as reference materials. You also are encouraged to explore those tutorials that are not included into the course. https://programminghistorian.org/lessons/ * Paul Vierthaler’s “Hacking the Humanities Tutorials” (Python), https://www.youtube.com/playlist?list=PL6kqrM2i6BPIpEF5yHPNkYhjHm-FYWh17 0.7 Software, Tools, &amp; Technologies: The following is the list of software, applications and packages that we will be using in the course. Make sure to have them installed by the class when we are supposed to use them. Zotero, https://www.zotero.org/; MS Word or Apache OpenOffice (you most likely already have one of these) [Mac] Terminal / [Windows] Powershell (both are already on your machines) Python https://www.python.org/ git and https://github.com/, version control system pandoc (https://pandoc.org/), markdown, bibTeX (bibliographical format for LaTeX) QGIS, a Free and Open Source Geographic Information System (https://qgis.org/en/site/) Regular expressions, EditPad Pro/Sublime Text Wget (https://www.gnu.org/software/wget/), a free software package for retrieving files [TEI] XML, csv/tsv, json, yml, etc. Gephi (https://gephi.org/) 0.8 Submitting Homework: Homework assignments are to be submitted by the beginning of the next class; For the first few classes you must email them to the instructor (as attachments) Later, you will be publishing your homework assignments on your github pages and sending an email to the instructor informing that you have completed your homework and providing a relevant github link. In the subject of your email, please, use the following format: CourseID-LessonID-HW-Lastname-matriculationNumber, for example, if I were to submit homework for the first lesson, my subject header would look like: 070112-L01-HW-Romanov-12435687. DH is a collaborative field, so you are most welcome to work on your homework assignments in groups, however, you must still submit it. That is, if a groups of three works on one assignment, there must be three separate submissions: either emailed from each member’s email and published at each member’s github page. 0.9 Schedule Location: Online 00 - Mo, 11. Okt. 2021 - 12:00-14:00 01 - Mo, 18. Okt. 2021 - 12:00-14:00 02 - Mo, 25. Okt. 2021 - 12:00-14:00 03 - Mo, 01. Nov. 2021 - 12:00-14:00 04 - Mo, 08. Nov. 2021 - 12:00-14:00 05 - Mo, 15. Nov. 2021 - 12:00-14:00 06 - Mo, 22. Nov. 2021 - 12:00-14:00 07 - Mo, 29. Nov. 2021 - 12:00-14:00 08 - Mo, 06. Dez. 2021 - 12:00-14:00 09 - Mo, 13. Dez. 2021 - 12:00-14:00 10 - Mo, 03. Jan. 2022 - 12:00-14:00 11 - Mo, 10. Jan. 2022 - 12:00-14:00 12 - Mo, 17. Jan. 2022 - 12:00-14:00 13 - Mo, 24. Jan. 2022 - 12:00-14:00 0.10 Lesson Topics (subject to modification) [ #01 ] Citation Management and Academic Writing I - with Zotero and MS Word or Open Office [ #02 ] “Off with the Interface!” Getting to know the command line [ #03 ] Version Control and Collaboration: Github.com [ #04 ] Citation Management and Academic Writing II - with Pandoc, markdown, Zotero/BibTex [ #05 ] Constructing robust searches with Regular expressions [ #06 ] Webscraping with Wget, preparing URLs with Python and other tools // “The Dispatch” [ #07 ] Understanding Structured Data [ #08 ] Converting data into different formats // “The Dispatch” [ #09 ] Extracting tagged data for analysis // “The Dispatch” [ #10 ] Graphing chronological data // “The Dispatch” [ #11 ] Mapping data // “The Dispatch” [ #12 ] Topic modeling &amp; TF-IDF // “The Dispatch” [ #13 ] Social Network Analysis (with Gephi); modeling network data // “The Dispatch” "],["lesson-01-academic-writing-i.html", "1 Lesson 01: Academic Writing I 1.1 Bibliography Managers 1.2 Zotero 1.3 Homework", " 1 Lesson 01: Academic Writing I 1.1 Bibliography Managers Bibliography managers make your life easier when it comes to collectin, organizing and maintaining bibliographical references and your library of electronic publications (most commonly as PDFs). Additionally, they are an indispensable writing tool as they take care of formatting (and reformatting) references and bibliographies in any writing project that you might undertake. There are plenty of different programs out there with their advantages and disadvantages (for example, Mendeley, RefWorks, Citavi, Endnote, Papers, Zotero, and quite a few more). We will use Zotero—it is being developed by scholars for scholars; it is free and open source; it does pretty much everything you might possibly need from a program of this kind. 1.2 Zotero 1.2.1 Getting Started Zotero can be installed from here: https://www.zotero.org/download/; the page will offer you a version suitable for your operating system, but you should also see the links to versions for specific systems (Mac OS, Windows, Linux). During installation Zotero should automatically integrate into your browser (like Chrome or Firefox) and into your word processor (MS Word, LibreOffice, GoogleDocs are supported). It is possible that you may have to do that manually. Zotero Connector for Chrome can be installed from the same page (https://www.zotero.org/download/) detailed explanations on how to use word processor plugins can be found here; you can use Zotero with MS Word, LibreOffice and Google Docs; in case you cannot get your plugin activated, check the Troubleshooting Section. 1.2.2 Main Functionality You need to be able to do the following tasks with your Zotero in order to take full advantage of its functionality. Online Tutorials: If you prefer video tutorials, you can check a series of tutorials prepared by the McGill Library (there are also plenty other tutorials on YouTube :); if you prefer to read, you can check a series of tutorials prepared by the UC Berkley Library. Adding bibliographical records (and PDFs) Using Zotero Connector: the easiest way to add a reference is from a browser with Zotero connector. This can be done practically from any library or journal database (e.g., Uni Wien Library, Worldcat.org, JSTOR); simply click the connector button while you are on a page with a publication that you want to add to your Zotero database. PDF may be automatically downloaded, if available; keep in mind that in places like JSTOR you need to agree to terms before this function will work; what you need to do is to download one PDF manually from a JSTOR page, where you will be asked to agree to terms of their services; Drag-and-dropping PDFs into Zotero; this however works only when Zotero can parse relevant bibliographical information from a PDF; This might be a good way to start if you already have lots of PDFs that you want to add to Zotero. Using Unique Identifiers: you can use ISBN or DOI numbers. Using Import: you can import bibliographical data from another application or from bibliographical files (formats, like RIS, which you can download from most libraries as well). Manually: you can manually add and fill in a record as well. Write-and-cite Detailed Instructions: MS Word, LibreOffice and Google Docs; you can also check the video tutorial. Add a citation Customize a citation (by adding prefixes, suffixes, page range for a specific reference, etc.). Change citation style. For example, change from Chicago Manual of Style to Universität Wien - Institut für Geschichte (Yes, there is this specific citation style for Zotero: https://www.zotero.org/styles?q=id%3Auniversitat-wien-institut-fur-geschichte); in order to do that you need to download the IfG style and install it into Zotero. You can find lots of different citation styles here: https://www.zotero.org/styles; to add a new style to Zotero: download the style you want. Open Zotero. Go to Preferences (under Zotero, Edit, or Tools — depending on your system). Click the “Cite” button. Click the “Styles” tab. Click the + button at the bottom right. Select the style file you saved in the first step. Generate and update bibliography in your paper. NB: If you use Zotero plugin for adding your citations, they remain connected to Zotero and can be automatically reformatted; you can also drag-and-drop any bibliographical record into any text editor—the reference will be formatted according to the currently selelected style, but it will not be connected to Zotero and cannot be reformatted automatically later. General Maintenance and Organization Zotero can [automatically] rename PDFs using metadata, although the default function is not very robust (see, Zotfile plugin below). You can create “collections” and drag-and-drop publications relevant to a specific topic or project you are working on. 1.2.3 Additional Functionality: Plug-Ins There is a variety of third-party plugins that you can add to Zotero for additional functionality. The list of plugins can be found at https://www.zotero.org/support/plugins. To install a plugin, you need to download its .xpi file to your computer. Then, in Zotero, click “Tools → Add-Ons”, then drag the .xpi for the plugin onto the Add-Ons window that opens. Two plugins will be of particular interest to us: Zotfile and BetterBibTeX. 1.2.4 Zotfile Zotfile (http://zotfile.com/) is a Zotero plugin to manage your attachments: automatically rename, move, and attach PDFs (or other files) to Zotero items, sync PDFs from your Zotero library to your (mobile) PDF reader (e.g. an iPad, Android tablet, etc.) and extract annotations from PDF files. This plugin is particularly helpful for organizing PDFs on your hard drive. By default, Zotero saves PDFs in a computationally safe, but humanely incomprehensible manner: each PDF, even if it is renamed from bibliographical metadata and is human readable, it is still placed into a folder whose name is a random sequence of characters. Zotfile allows you to organize PDFs in a more human-friendly manner. The first screenshot below shows Zotero default mode, while the second one shows Zotfile mode: essentially, Zotfile creates a folder for each author and PDFs of all publications by that author get placed in that folder. You can sync this folder with Dropbox or other cloud service and access it from your tablet or phone. Zotero default organization. Zotfile organization. 1.2.5 Better BibTeX for Zotero For a moment this will not be an immediately useful plug-in, but it is the most important one for our Memex project. This plugin exports bibliographical data into a bibTeX format, which is very easy to process with python scripts (it also generates citation keys which can be used for citation in markdown, which we will cover later). The two screenshots below show how the same record looks in Zotero preview and in the bibTeX format. A Record in Zotero. The Same Record in BibTeX Format. 1.3 Homework collect 30-50 bibliographic records into your Zotero (ideally with PDFs); the number may seem like a lot, but you will see that you can do that it will take only about 30 mins on JSTOR; those of you who are already using Zotero must already have more than 50 records in your databases. clearly, you should be collecting items that are relevant to your fields of study and your research; organize them into folders, if that is necessary; create Bibliography and email it to me (this is one-click operation; try to figure on your own how to do this; asking on Slack counts); make sure that you are comfortable with the main functionality of Zotero; that you have the discussed plugins installed; to get comfortable with the main functionality, you should practice each listed procedure at least a couple of times. in preparation for the next class, please, watch the following two short videos from Dr. Paul Vierthaler’s Hacking the Humanities series: Episode 1: Introduction to the Hacking the Humanities Tutorial Series and install Python via Anaconda; you can also install Python directly from https://www.python.org/, but Anaconda distribution might make your life easier, especially if you are on Windows. Episode 2: The Command Prompt. Submitting homework: Homework assignment must be submitted by the beginning of the next class; Email your homework to the instructor as attachments. * In the subject of your email, please, add the following: CCXXXXX-LXX-HW-YourLastName-YourMatriculationNumber, where CCXXXXX is the numeric code of the course; LXX is the lesson for which the homework is being submitted; YourLastName is your last name, and YourMatriculationNumber is your matriculation number. "],["lesson-02-command-line.html", "2 Lesson 02: Command Line 2.1 Command Line 2.2 Homework", " 2 Lesson 02: Command Line 2.1 Command Line The knowledge of “command line” opens a whole new world of opportunities, as the number of interface-less programs and applications is significantly larger; command line also offers a more robust and direct controls over a computer. The main goal is to learn the basics of this indispensable tool. We can use Terminal on Mac (installed), Powershell on MS Windows (should be installed), although other command line tools will work as well. Before we proceed, however, let’s discuss a few concepts: What a filesystem is How to run a program from the command line What it means to run a program How the computer knows what program to run How to refer to a file from the command line 2.1.1 The filesystem Every disk contains a filesystem and information about where disk data is stored and how it may be accessed by a user or application. A filesystem typically manages operations, such as storage management, file naming, directories/folders, metadata, access rules and privileges. Commonly used file systems include File Allocation Table 32 (FAT 32), New Technology File System (NTFS) and Hierarchical File System (HFS). All the files and programs on your computer are organized into folders; all these folders are in some other folders all the way down to your hard drive, which we call the root of your filesystem. Every hard drive, USB drive, DVD, and CD-ROM has its own filesystem. You normally look at the contents of your filesystem via the Finder (on Mac) or the Explorer (on Windows). Open a window there now. The Finder / Explorer window opens in some folder, which might be different depending on what computer operating system you’re using. But you’ll usually have a navigation bar to the left, that will let you go to different places. You see folders, also known as directories, and you might see files too. One thing that computer OSes like to hide from you is the fact that you have a home directory, where all your personal files and folders should live. This makes it easier for multiple users to use a single computer. You can find your home directory like this: On Mac, select Go &gt; Home in the menu. On Windows, click on Local Drive (C:), then click on Users, then click on your login name. You’ll see that your home directory has several folders in it already, that were created automatically for you when you first made a user account. Now how can you tell where you are, with respect to the root of your drive? On Mac, select View &gt; Show Path Bar in the menu. On Windows, look: The Finder / Explorer will also show you where in your computer’s filesystem you are. This is called the path—it shows you the path you have to take from the root of your filesystem to the folder you are in. Now if you are on Windows, click on that bar and you’ll see something surprising. This is your real path. The C:\\ is how Windows refers to the root of your filesystem. Also note that, even if your OS is not in English, the path may very well be! 2.1.2 Getting started with the command line Now that you have a hint of what is going on behind the scenes on your computer, let’s dive into the command line. Here is how you get there: On Mac, look for a program called Terminal.app On Windows, look for a program called Powershell By default, these shells open in your home directory. On Windows this is easy to see, but on Mac it is less clear—that is, until you know that this ~ thing is an alias for your home directory. 2.1.3 Components of the command line The command line consists of a prompt where you type your commands, the commands and arguments that you type, and the output that results from those commands. The prompt is the thing that looks like (where user is your username): MacBook-Pro:~ user$ or PS C:\\Users\\user&gt; You will never need to type the prompt. That means that, if you are noting down what we do in class for future reference, you should not copy this part! The prompt actually gives you a little bit of information. On Mac, it has the name of the computer, followed by a :, followed by the directory where you are, followed by your username, with $ at the end. On Windows, it has PS for PowerShell, followed by the name of the drive (C for most of you), followed by a :, followed by the full path to where you are, with &gt; at the end. When you type a command, nothing happens until you press the Return/Enter key. Some commands have output (more text that appears after you press Return/Enter) and others don’t. You cannot run another command until the prompt is given again. NOTE: From this point on, you will be running the commands that are run here! Let’s first make sure we are in our home directory by typing cd ~. For most of you this should change nothing, but now you know your first shell command. The cd stands for change directory, and what follows is the directory you want to go to. cd ~ Now let’s have a look around. The command to show what is in any particular directory is called ls, which stands for list. Try running it. ls If you are on Windows, what you get will look more like this: PS C:\\Users\\user&gt; ls You should then see something like: Verzeichnis: C:\\Users\\user Mode LastWriteTime Length Name ---- ------------- ------ ---- d---- 23.02.2016 21:18 .oracle_jre_usage d-r-- 23.02.2016 20:40 Contacts d-r-- 23.02.2016 20:40 Desktop d-r-- 23.02.2016 21:11 Documents d-r-- 23.02.2016 21:16 Downloads d---- 23.02.2016 21:24 exist d-r-- 23.02.2016 20:40 Favorites d-r-- 23.02.2016 20:40 Links d-r-- 23.02.2016 20:40 Music d-r-- 23.02.2016 20:40 Pictures d-r-- 23.02.2016 20:40 Saved Games d-r-- 23.02.2016 20:40 Searches d-r-- 23.02.2016 20:40 Videos PS C:\\Users\\user&gt; Now go into your documents folder and look around. cd Documents ls How does this compare to what you see in the Finder / Explorer window, if you click on the Documents folder? Another important command, which tells you where you are at any given time, is pwd. This means print working directory. Try it now and see what you get. pwd If ever you get lost on the command line, pwd will always help you find your way. 2.1.4 File paths and path notations By now you will have noticed that I’ve mentioned the path a few times, and that it seems to have something to do with this thing that pwd prints out. (And, most annoyingly, that it looks different on Mac and Windows) The bit of text that you get from pwd is what is called path notation, and it is very important that you learn it if you want to do anything with your own digital data. Here are some rules: The / (or \\\\ on Windows) separates folder names. So Desktop/Video means “the thing called Video inside the Desktop folder”. The / all by itself refers to the base of your hard drive (usually Macintosh HD or C:\\.) The ~ refers to your home folder. These things can be combined; ~/Documents means “the Documents folder in my home folder.” The . means “the current working directory”, i.e. what you would get if you ran the command pwd. The .. means “one directory back”—if pwd gives you /Users/user, then .. means /Users. If the path does not start with a . or a / or a ~, then it will be assumed to start with a ./, that is, “start from the current working directory.” Let’s wander around a bit. But, first, let’s download a zip file with some materials for this class. Unzip it somewhere and go to that folder in your Terminal or Powershell. cd /path/to/the/folder/tnt_practice_materials pwd cd ./cd 02_CommandLine/ pwd ls Try the following if you are on Mac ls -lh cd .. pwd NB: you can use TAB to autocomplete the path: type ls to see what folders are in Documents, then go to any one of them by typing cd (space) and then the first two letters &gt; after that use TAB and the name will be complete automatically. cd 03[TAB] pwd cd ../01[TAB] pwd ls McCarty_Modeling.pdf cd .. 2.1.5 Command line arguments So far we have learned three commands: cd, ls, and pwd. These are useful for navigation, but we can run a lot more commands once we learn them, and have a need for them! What are we doing, exactly? First word is the command All other words are the arguments Words must be separated by spaces cd is a command that expects an argument: the name of the directory you want to go to. But what if the name has a space in it? NB: You may think of most commands as sentences with subject, predicate, and object (or multiple objects). cd ./01_Zotero_Word/Green Eggs and Ham What happened there? Well, we have a folder called Green Eggs and Ham in our example, and we tried to go there. But since the command line works with arguments, and since arguments are separated by space, the machine interpreted this as if we were saying “Change to the ./01_Zotero_Word/Green folder, and then Eggs, and, Ham, whatever that means.” And it gave us an error, because we don’t have a folder called Green in our example. You can get around this. How you get around it depends on whether you’re on Windows or not. One way to get around it that should work both places is like this: On Windows: cd &#39;./01_Zotero_Word/Green Eggs and Ham&#39; On Mac (you need to escape spaces by adding a backslash in front of them): cd ./01_Zotero_Word/Green\\ Eggs\\ and\\ Ham/ NB: The easiest solution is to use TAB for autocomplete! 2.1.6 More commands With command line you can do everything that you became accustomed to be doing in a graphical interface of your favorite file manager. For example, you can copy, move, and delete files and folders. You can use: mv to move files rm (on Windows also: del) to remove/delete files cp to copy files In all cases you need to state which files you want to mv, rm, or cp. In some cases you also need to point where you want to mv or cp your files. NB: Syntax on Mac and Windows will vary slightly, but if you keep using [TAB] for autocompletion, there will be no different in the process of typing the command, so let’s try to do it this way. To start, let’s go to the root directory of our course materials. From there, let’s do the following: cd 01[TAB] ls cp Mc[TAB] Green[TAB] cd Green[TAB] ls NB: when you hit [TAB] after Mc you are not going to get the full autocomplete, because there are two files that start with McCarty_Modeling—one is pdf and another—txt. You will need to type one more letter p and then hit [TAB] again to get the file name that you need. Thus, the command can be transcribed as: M[TAB]p[TAB] Now let’s rm (delete) the McCarty_Modeling.pdf from this folder, then go to the folder where we copied it, and then mv (move) it back to where it was in the first place. rm M[TAB]p[TAB] ls cd G[TAB] mv Mc[TAB] ../ cd .. ls Tada! The McCarty_Modeling.pdf should now be back where it was. If you want to learn about new commands, try to google. Googling things like this is a very big part of being a DH scholar! You will most likely find your answers on https://stackoverflow.com/, which will become your most frequented resource, if you embark on the DH path. 2.2 Homework Command line Watch again a short video on Command Prompt in Dr. Vierthaler’s Hacking the Humanities series: Episode 2: The Command Prompt. Work through the following materials on command line which is relevant to your operating system. Ted Dawson, “Introduction to the Windows Command Line with PowerShell,” The Programming Historian 5 (2016), https://programminghistorian.org/en/lessons/intro-to-powershell. Ian Milligan and James Baker, “Introduction to the Bash Command Line,” The Programming Historian 3 (2014), https://programminghistorian.org/en/lessons/intro-to-bash. Python Work through Chapter I of Zelle’s book; read the entire chapter; retype and run all code snippets as described in the book; work through the chapter summary and exercises; complete all programming exercises; For submission: email me the results of “Programming Exercises”. In your submission there should be text files or python script files for exercises 1 (results of print function), 3, 4, 5, 7. Each python script should be working, i.e. you should be able to run it and get relevant results. You are welcome to discuss any of these assignments on Slack. Work through the following videos from Dr. Vierthaler’s Hacking the Humanities series: Episode 3: The Very Basics of Python Episode 4: Strings Episode 5: Integers, Floats, and Math in Python NB: The best way to work through these tutorials is to repeat all steps after the instructor. You can find the scripts at https://github.com/vierth/humanitiesTutorial. Submitting homework: Homework assignment must be submitted by the beginning of the next class; Email your homework to the instructor as attachments. In the subject of your email, please, add the following: CCXXXXX-LXX-HW-YourLastName-YourMatriculationNumber, where CCXXXXX is the numeric code of the course; LXX is the lesson for which the homework is being submitted; YourLastName is your last name, and YourMatriculationNumber is your matriculation number. "],["lesson-03-version-control.html", "3 Lesson 03: Version Control 3.1 Version Control and Collaboration 3.2 Setting-up git 3.3 General git workflow 3.4 Main git Commands 3.5 Some useful command line commands to remember 3.6 Practice 3.7 Homework", " 3 Lesson 03: Version Control 3.1 Version Control and Collaboration Version control systems are extremely helpful for the development of DH projects, which are often lengthy and complex and require organic collaboration. Git and GitHub are currently the most popular tools of this kind. In fact, it is difficult to imagine a DH project that would not rely on the use of git and GitHub. Before we begin, make sure to: Create a github account at https://github.com/, if you do not have one yet. Download and install git software: for Windows: you can download it from https://git-scm.com/download/win. Please, choose 64-bit Git for Windows Setup. you can also install a portable version of git which does not require installation https://git-scm.com/download/win. For this, choose 64-bit Git for Windows Portable. Simply download and unzip (Suggestion: move that unzipped folder to the folder where you keep all class-related files and materials). In the folder, run git-bash.exe (for a more Unix-like command line) or git-cmd.exe (for Windows command line). for Mac: try to run git --version from Terminal. If git is not installed, you will be prompted to install Xcode Command Line Tools which comes with git among other things. This is the easiest way. Note: there are also interface tools for github. We will not be working with them in the class, but you are welcome to test them on your own at home. See, https://desktop.github.com. The main reason for this is because interface tools will be different for different operating systems, while the command line usage will be exactly the same across all platforms. In class we will cover the following: Basic git functionality; Starting a github-based website; Basics of markdown; 3.2 Setting-up git git config --global user.name \"YourName\" git config --global user.email \"YourEmail\" 3.3 General git workflow In Terminal (on Mac) or Git-Bash (on Windows) create a repository under your account online at https://github.com. Alternatively, you can also fork somebody else’s repository.1 clone (NB: this is done on https://github.com!) work add commit push / pull send pull request (NB: this is done on https://github.com) Note: Steps 2 and 8 are relevant only when you work on a project (repository) that is owned by somebody else. If you work on a repository that you created under your account, you only need steps 1, 3-7. Below is a visual representation of this cycle. 3.4 Main git Commands git clone &lt;link&gt; clones/downloads a repository on you machine git status shows the current status of the repository (new, changed, deleted) git add . adds all new files and modified files to the repository git commit -m \"message\" saves all files in their current state into the repository, and created a milestone git push origin master uploads changes to https://github.com origin is a specific repository you are pushing your changes to; it is automatically set up, when you clone a repository on your computer. master is the branch you are pushing to the repository; master is the default name of the main branch in a git repository. To check the names of your branches, you can type git branch. NB: sometimes you may get an error, which in most cases means that you need to pull first git pull origin master downloads changes from https://github.com git log shows the history of commits; here you can choose where you want to roll back, in case of troubles. 3.5 Some useful command line commands to remember pwd shows you where you are on a drive (gives you path) ls / dir [on Windows] shows everything in the your current location/folder cd &lt;name of the folder&gt; takes you to that folder cd .. takes you one level up in the tree structure of your computer 3.6 Practice Under your GitHub account, create repository HW070172; clone it to your computer (use command line: git clone LinkToYourRepository); Now, in the repository: let’s edit README.md (create it, if you have not yet); add some text into this file create subfolders for Lessons, like L01, L02, L03, etc. copy/paste your homework files in respective subfolders. Now, do the add-commit-push routine to upload the files to your repository Now, online: check if your files are there let’s do some edits to the README.md file (markdown basics / github flavor) pull / push 3.7 Homework Git and GitHub Watch a video on Git &amp; GitHub in Dr. Vierthaler’s Hacking the Humanities series: Supplement 1: A quick Git and Github Tutorial. This will help you to go over the new material and pick up a few more useful git &amp; gitHub tricks. There is an interface for github that you can also use, but I strongly recommend to use command line; interfaces change, but commandline commands remain the same! Daniel van Strien. 2016. “An Introduction to Version Control Using GitHub Desktop,” The Programming Historian 5, https://programminghistorian.org/. Please, also read (for markdown): Simpkin, Sarah. 2015. “Getting Started with Markdown.” Programming Historian, November. https://programminghistorian.org/. More on github-flavored markdown: https://guides.github.com/features/mastering-markdown/. On markdown for academic writing, see https://pandoc.org/MANUAL.html. A cheat-sheet &amp; interactive tutorial for your practice: https://commonmark.org/help/. Extra: you can build and host a website on github.com; your website will have the name: YourUserName.github.io — you can create a repository with that name and build your website there using Jekyll and GitHub Pages. Any other repository may also be converted into a part of your website, which will be accessible at YourUserName.github.io/YourRepository/ Visconti, Amanda. 2016. “Building a Static Website with Jekyll and GitHub Pages.” Programming Historian, April. https://programminghistorian.org/. Python Work through Chapter II of Zelle’s book; read the entire chapter; retype and run all code snippets as described in the book; work through the chapter summary and exercises; complete all programming exercises; Watch Dr. Vierthaler’s videos: Episode 04: Strings; Episode 05: Integers, Floats, and Math in Python; Episode 06: Lists Submitting homework Homework assignment must be submitted by the beginning of the next class; Now, that you know how to use GitHub, you will be submitting your homework pushing it to github: Create a relevant subfoler in your HW070172 repository and place your HW files there; push them to your GitHub account; Email me the link to your repository with a short message (Something like: I have completed homework for Lesson 3, which is uploaded to my repository … in subfolder L03) In the subject of your email, please, add the following: CCXXXXX-LXX-HW-YourLastName-YourMatriculationNumber, where CCXXXXX is the numeric code of the course; LXX is the lesson for which the homework is being submitted; YourLastName is your last name, and YourMatriculationNumber is your matriculation number. "],["lesson-04-sustainable-academic-writing.html", "4 Lesson 04: Sustainable Academic Writing 4.1 markdown, pandoc, the *TeX family, and obsidian 4.2 Class Notes 4.3 pandoc Commands 4.4 Analytical Writing with markdown 4.5 Zettelkasten with Obsidian 4.6 Reference Materials: 4.7 Homework 4.8 Appendix: TEXT for your main.md file.", " 4 Lesson 04: Sustainable Academic Writing 4.1 markdown, pandoc, the *TeX family, and obsidian Introduction to sustainable academic writing that avoids any proprietary software solutions and formats. Before the class, make sure to install the following. pandoc (follow instructions on https://pandoc.org/installing.html) LaTeX engine (install from here: https://miktex.org/) LaTeX for Mac: MikTeX seems to be very finicky with Macs. The following solution proves to be more manageable and stable (you need to run this command in Terminal): brew install librsvg python homebrew/cask/basictex (from Pandoc page); after that missing packages might have to be installed manually, but that is relatively easy — the sustem will prompt you to install them, and that needs to be done only once; alternatively, one can install MacTeX (this one is quite large, about 4Gb). markdown Obsidian (https://obsidian.md/) 4.2 Class Notes Files: Download the following archive file: sustainable_writing.zip. Make sure to unzip it! It contains the following files: biblio.bib—a bibliography file; cms-fullnote.csl—a citation style; main.md—the main text file (its contents are also shown below); NB: remember that all files must be in the same folder; it makes sense to put folders into a subfolder (not to overcrowd your main folder), but then do not forget to change the path in your image code. (The text of the main.md file is also given at the very end of the lesson.) 4.3 pandoc Commands (a quick demo) NB: On Windows, you may see a pop-up Windows from MikTex asking to download a missing package for LaTeX. This means that some package is missing and you need to download it (or several of them). Uncheck a birdie to install all necessary packages at once. After that everything should work. First try to convert to docx or html. These two formats do not require LaTeX. pandoc -f markdown -t docx -o main.docx --filter pandoc-citeproc main.md pandoc -f markdown -t html -o main.html --filter pandoc-citeproc main.md pandoc -f markdown -t epub -o main.epub --filter pandoc-citeproc main.md pandoc -f markdown -t latex -o main.pdf --filter pandoc-citeproc main.md NB: it may so happen that your version of pandoc will complain about --filter pandoc-citeproc. If that happens, your commands should look like the following: pandoc -f markdown -t docx -o main.docx --citeproc main.md pandoc -f markdown -t html -o main.html --citeproc main.md pandoc -f markdown -t epub -o main.epub --citeproc main.md pandoc -f markdown -t latex -o main.pdf --citeproc main.md Comment: -f means “convert from a specific format”. -t means “convert to a specific format”. Thus, the whole command (say, the first one) reads as follows: pandoc converts from (-f) markdown to (-t) latex, then outputs (-o) main.pdf, to which a ‘filter’ that processes citations (--filter pandoc-citeproc) is applied; and the file to which this all is applied is main.md. 4.4 Analytical Writing with markdown You can find a number of blogposts online about how different scholars are using markdown to write their academic works. For example, Scott Selisker, an Associate professor at the Department of English at the U Arizona, shares his experience of writing his using a popular text editor Atom (https://atom.io/), which allows one to integrate writing in markdown with the helpfulness of Zotero, as well as offers quite a few other nice features. (You can find how to set everything up in Scott Selisker’s blog post: http://u.arizona.edu/~selisker/post/workflow/.) 4.5 Zettelkasten with Obsidian One of the most useful pieces of software for the purpose of analytical writing is Obsidian (https://obsidian.md/), which is available for all major operating systems. The developers of Obsidian call is “a powerful knowledge base on top of a local folder of plain text markdown files”. The design of the program gives you the complete control over your data as there are no proprietary formats which may make your data inaccessible and no complicated technologies that hide your data in difficult-to-access formats (like, MySQL, for example). The main power of Obsidian is that it allows you to connect your notes into a network of information, which makes it nearly perfect for complex analytical writing projects where you want to have an option to branch your writing into multiple directions and then reassemble your main argument by including and excluding parts of these branches. This method of academic writing has been most famously formalized by the German sociologist Niklas Luhmann, who came up with a paper-based slip-box system (Zettelkasten) which he used to produce some 50 books and 550 articles (Schmidt 2016, 289). There are lots of materials written about the Zettelkasten system—many of them, for obvious reasons, are in German. One of the best expositions of the method is Sönke Ahrens’s How to Take Smart Notes: One Simple Technique to Boost Writing, Learning and Thinking – for Students, Academics and Nonfiction Book Writers, which is an English version of his Das Zettelkasten-Prinzip: Erfolgreich wissenschaftlich Schreiben und Studieren mit effektiven Notizen. (See: Ahrens 2017; for more: Luhmann 1982; Schmidt 2014, 2018, 2016). There are several videos on YouTube, where Sönke Ahrens discusses his book in great details (for example, this and this). How to with/in Obsidian (a quick demo): using markdown; creating notes; linking notes; creating branches; creating a network; crafting the final narrative/argument; 4.6 Reference Materials: Simpkin, Sarah. 2015. “Getting Started with Markdown.” Programming Historian, November. https://programminghistorian.org/lessons/getting-started-with-markdown. Tenen, Dennis, and Grant Wythoff. 2014. “Sustainable Authorship in Plain Text Using Pandoc and Markdown.” Programming Historian, March. https://programminghistorian.org/lessons/sustainable-authorship-in-plain-text-using-pandoc-and-markdown. 4.7 Homework Convert a plain text paper into markdown and convert it with Pandoc into a PDF, MS Word, and HTML documents. Plain text file for the task: McCarty_Modeling.txt Use this PDF file as a guide for your formatting: McCarty_Modeling.pdf Convert only the first 7 pages. You can skip up to 1/3 of bibliographical records, if you cannot find them online. Alternatively, you can use any of your own papers that you have already written: 5 pages, 10 footnotes, 5 bibliography items. I would say this is preferable, since it will give you a better idea of how these tools work together. Python Work through Chapters 3 and 5 of Zelle’s book; read chapters carefully; work through the chapter summaries and exercises; complete the following programming exercises: 1-8 in Chapter 3; 1-7 in Chapter 5; Watch Dr. Vierthaler’s videos: Episode 07: Booleans (and Boolean Operators) Episode 08: Loops (and file objects) Submitting homework: Homework assignment must be submitted by the beginning of the next class; Now, that you know how to use GitHub, you will be submitting your homework pushing it to github: Create a relevant subfoler in your HW070172 repository and place your HW files there; push them to your GitHub account; Email me the link to your repository with a short message (Something like: I have completed homework for Lesson 3, which is uploaded to my repository … in subfolder L03) In the subject of your email, please, add the following: CCXXXXX-LXX-HW-YourLastName-YourMatriculationNumber, where CCXXXXX is the numeric code of the course; LXX is the lesson for which the homework is being submitted; YourLastName is your last name, and YourMatriculationNumber is your matriculation number. 4.8 Appendix: TEXT for your main.md file. --- title: | *From*: &quot;Modeling: A Study in Words and Meanings&quot; by Willard McCarty subtitle: author: date: \\today bibliography: biblio.bib csl: cms-fullnote.csl --- &gt;&gt; Out on site, you were never parted from your plans. They were your Bible. They got dog-eared, yellowed, smeared with mud, peppered with little holes from where you had unrolled them on the ground. But although so sacred, the plans were only the start. Once you got out there on the site everything was different. No matter how carefully done, the plans could not foresee the *variables*. It was always interesting, this moment when you saw for the first time the actual site rather than the idealised drawings of it. &gt;&gt; Kate Grenville, *The Idea of Perfection* (Sydney: Picador, 1999): 62–3 # Introduction The question of modeling arises naturally for humanities computing from the prior question of what its practitioners across the disciplines have in common. What are they all doing with their computers that we might find in their diverse activities indications of a coherent or cohesible practice? How do we make the best, most productive sense of what we observe? There are, of course, many answers: practice varies from person to person, from project to project, and ways of construing it perhaps vary even more. In this chapter I argue for modeling as a model of such a practice. I have three confluent goals: to identify humanities computing with an intellectual ground shared by the older disciplines, so that we may say how and to what extent our field is of as well as *in* the humanities, how it draws from and adds to them; at the same time to reflect experience with computers &quot;in the wild&quot;; and to aim at the most challenging problems, and so the most intellectually rewarding future now imaginable. My primary concern here is, as Confucius almost said, that we use *the correct word* for the activity we share lest our practice go awry for want of understanding (*Analects 13.3*). Several words are on offer. By what might be called a moral philology I examine them, arguing for the most popular of these, &quot;modeling.&quot; The nominal form, &quot;model&quot;, is of course very useful and even more popular, but for reasons I will adduce, its primary virtue is that properly defined it defaults to the present participle, its semantic lemma. Before getting to the philology I discuss modeling in the light of the available literature and then consider the strong and learned complaints about the term. # Background Let me begin with provisional definitions[^1]. By &quot;modeling&quot; I mean *the heuristic process of constructing and manipulating models*, a &quot;model&quot; I take to be either *a representation of something for purposes of study*, or *a design for realizing something new*. These two senses follow Clifford Geertz&#39;s analytic distinction between a denotative &quot;model *of*&quot; such as a grammar describing the features of a language, and an exemplary &quot;model *for*&quot; such as an architectural plan [@geertz_interpretation_2017, 93][^2]. In both cases, as the literature consistently emphasizes, a model is by nature a simplified and therefore fictional or idealized representation, often taking quite a rough-and-ready form: hence the term &quot;tinker toy&quot; model from physics, accurately suggesting play, relative crudity, and heuristic purpose [@cartwright_how_1984, 158]. By nature modeling defines a ternary relationship in which it mediates epistemologically, between modeler and modeled, researcher and data or theory and the world [@morgan_models_1999]. Since modeling is fundamentally relational, the same object may in different contexts play either role: thus, e.g., the grammar may function prescriptively, as a model for correct usage, the architectural plan descriptively, as a model of an existing style. The distinction also reaches its vanishing point in the convergent purposes of modeling: the model of exists to tell us that we do not know, the model for to give us what we do not yet have. Models *realize*. [^1]: My definitions reflect the great majority of the literature explicitly on modeling in the history and philosophy of the natural sciences, especially of physics. The literature tends to be concerned with the role of modeling more in formal scientific theory than in experiment. The close relationship between modeling and experimenting means that the rise of a robust philosophy of experiment since the 1980s is directly relevant to our topic; see [@hacking_stability_1988]. Quite helpful in rethinking the basic issues for the humanities are the writings from the disciplines other than physics, e.g., [@clarke_models_2015] on archaeology; on the social sciences, the essays by de Callatay, Mironesco, Burch, and Gardin in [@franck_explanatory_2011]. For interdisciplinary studies see Shanin (1972) and [@morgan_models_1999], esp. &quot;Models as Mediating Instruments&quot; (pp. 10–37). [^2]: Cf. Goodman&#39;s distinction between &quot;denotative&quot; and &quot;exemplary&quot; models, respectively (1976: 172–3); H. J. Groenewold&#39;s &quot;more or less poor substitute&quot; and &quot;more or less exemplary ideal&quot; (1960: 98). Similar distinctions are quite common in the literature. # Bibliography References "],["lesson-05-robust-searches.html", "5 Lesson 05: Robust Searches 5.1 Constructing Robust Searches with Regular Expressions 5.2 regular expressions 5.3 Class materials 5.4 Digital materials 5.5 Reference Materials 5.6 Homework", " 5 Lesson 05: Robust Searches 5.1 Constructing Robust Searches with Regular Expressions 5.2 regular expressions In this lesson we will learn about regular expressions, an important semi-language for constructing complex searches. Any text editor that supports regular expressions will work fine for this lesson, but let’s all use Sublime Text (both Mac and Windows). The practical materials for this lesson can be downloaded from here: https://github.com/maximromanov/re_tutorial (simply download the zip file of the repository.) Open the practicum file in Sublime Text. 5.2.1 What are regular expressions?** very small language for describing textual patterns not a programming language, yet a part of each one incredibly powerful tool for find/replace operations old (1950s-60s) “arcane art” ubiquitous Source: https://xkcd.com/208/ 5.2.2 What would we use regular Expressions for? to search: all spelling variations of the same word: Österreich, Osterreich or Oesterreich.. words of specific morphological patterns: [search], [search]er, [search]ed, [search]ing, [search]es: all derivatives from the same root/word entities that may be referred to differently: references to Vienna in different languages? (Wien, Vienna, Вена, فيينا, etc.) references to Austria? (Vienna, Graz, Linz, Salzburg, Innsbruck, etc.) references to concepts: references to education in biographies: “s/he graduated from”, “s/he studied”, etc. to search and replace: reformat “dirty”/inconsistent data (OCR output, for example) to tag: make texts navigable and more readable tag information relevant to your research and many other uses… 5.2.3 The Basics A regular expression (can be shortened as regex or regexp) is a sequence of symbols and characters expressing a string or pattern to be searched for within a longer piece of text. In this sequence there are characters that match themselves (most characters) and there are characters that activate special functionality (special characters). For example: Vienna is a regular expression that matches “Vienna”; “Vienna” is a pattern; Question: if the pattern at matches strings with “a” followed by “t”, which of the following strings will it match?2 at hat that atlas aft Athens 5.2.4 Characters &amp; Special Characters most characters match themselves. matching is case sensitive. special characters: ()^${}[]\\|.+?*. to match a special character in your text, you need to “escape it”, i.e. precede it with “” in your pattern: – Osterreich [sic] **does not* match “Osterreich [sic]”. – Osterreich \\[sic\\] matches “Osterreich [sic]”. 5.2.5 Character Classes: [] characters within [] are choices for a single-character match; think of this as a type of either or. the order within [] is unimportant. x[01] matches “x0” and “x1”. [10][23] matches “02”, “03”, “12” and “13”. initial ^ negates the class: – [^45] matches any character except 4 or 5. Question: if the pattern [ch]at matches strings with “c” or “h” followed by “a”, and then by “t”, which of the following strings will this regular expression match?3: that at chat cat fat phat 5.2.6 Ranges (within classes) Ranges define sets of characters within a class. – [1-9] matches any number in the range from 1 to 9 (i.e., any non-zero digit) – [a-zA-Z] matches any letter of the English alphabet (ranges for specific languages will vary) – [12][0-9] matches numbers between 10 and 29 (i.e., the first digit is either 1 or 2; the second one—any digit) Ranges shortcuts Shortcut Name Equivalent Class \\d digit [0-9] \\D not digit [^0-9] \\w word [a-zA-Z0-9_] (actually more) \\W not word [^a-zA-Z0-9_] (actually more) \\s space [\\t\\n\\r\\f\\v ] \\S not space [^\\t\\n\\r\\f\\v ] . everything [^\\n] (depends on mode) Question: if the pattern /\\d\\d\\d[- ]\\d\\d\\d\\d/ matches strings with a group of three digits, followed by a space or a dash, and then—by another group of four digits, which of the following strings will this regular expression match?4: 501-1234 234 1252 652.2648 713-342-7452 PE6-5000 653-6464x256 5.2.7 Repeaters these special characters indicate that the preceding element of the pattern can be repeated in a particular manner: runs? matches “runs” or “run” 1\\d* matches any number beginning with “1” repeater count ? zero or one + one or more * zero or more {n} exactly n times {n,m} between n and m times {,m} no more than m times {n,} no less than n times Question: We have several patterns, which strings will they match?5 Patterns A) ar?t B) ar*t C) a[fr]?t D) ar+t E) a.*t F) a.+t Strings 1) “at” 2) “art” 3) “arrrrt” 4) “aft” 5.2.8 Lab: Intro (in the practicum file). 5.2.9 Anchoring anchors match between characters. anchors are used to assert that the characters you’re matching must appear in a certain place. for example, \\bat\\b matches “at work” but not “batch”. Anchor matches… ^ the beginning of a line or a string $ the end of a line of a string \\b word boundary \\B not word boundary 5.2.10 Alternation: “|” (pipe) in regex, “|” means “or” on the US keyboard layout, this character is in the vicinity of “Enter” and “Right Shift”. you can put a full expression to the left of the pipe and another full expression to the right, so that either one could match: seek|seeks|sought matches “seek”, “seeks”, or “sought”. seeks?|sought matches “seek”, “seeks”, or “sought”. 5.2.11 Grouping everything within ( … ) is grouped into a single element for the purposes of repetition or alternation: the expression (la)+ matches “la”, “lala”, “lalalala” (but not “all”). schema(ta)? matches “schema” and “schemata” but not “schematic”. grouping example: what regular expression would match “eat”, “eats”, “ate” and “eaten”? eat(s|en)?|ate NB: we can make it more precise by adding word boundary anchors to exclude what we do not need, like, for example, words “sate” and “eating”: \\b(eat(s|en)?|ate)\\b. 5.2.12 Lab: Part I (in the practicum file). 5.2.13 Replacement regular expressions are most often used for search/replace operations in text editors: Search Window: search pattern Replace Window: replacement pattern 5.2.14 Capture during searches, ( … ) groups capture patterns for use in replacement. special variables \\1, \\2, \\3, etc. contain the capture (in some text editors: $1, $2, $3). if we apply (\\d\\d\\d)-(\\d\\d\\d\\d) to “123-4567”: – \\1 (or, $1) captures “123” – \\2 (or, $2) captures “4567” 5.2.15 Capture &amp; Reformat How to convert “Schwarzenegger, Arnold” to “Arnold Schwarzenegger”? Search: (\\w+), (\\w+) Replace (a): \\2 \\1 Replace (b): $2 $1 NB: (!) Before hitting “Replace”, make sure that your match does not catch what you do NOT want to change 5.2.16 Lab: Part II (in the practicum file). Finding toponyms (placenames): very simple: Construct regular expressions that find references to all Austrian cities.6 a bit tricky: Construct regular expression that finds only cities from 1) Lower Austria; 2) Salzburg.7 5.2.17 To keep in mind regular expressions are “greedy,” i.e. they tend to catch more than you may need. Always test! test before applying! (In text editors Ctrl+Z (Win), Cmd+Z (Mac) can help to revert changes) check the language/application-specific documentation: some common shortcuts are not universal (for example, some languages/applications use \\1 to refer to groups, while others use $1 for the same purpose). 5.3 Class materials Presentation with all the slides: PDF (Windows PowerPoint Format) 5.4 Digital materials Online references: http://www.regular-expressions.info/ http://ruby.bastardsbook.com/chapters/regexes/ Interactive tutorial: http://regexone.com/ Cheat Sheets: http://krijnhoetmer.nl/stuff/regex/cheat-sheet/ http://www.rexegg.com/regex-quickstart.html 5.5 Reference Materials Goyvaerts, J. and Levithan, S. (2012). Regular Expressions Cookbook. Second edition. Beijing: O’Reilly. Amazon Link. Friedl, J. E. F. (2006). Mastering Regular Expressions. 3rd ed. Sebastapol, CA: O’Reilly. Amazon Link (I will share PDFs of these books via Slack; I strongly recommend to flip through the first book just to get an idea of what kind of things one can do with regular expressions.) 5.6 Homework Finish the practicum; push your answers to your github repository. Python Work through Chapters 6 and 7 of Zelle’s book; read chapters carefully; work through the chapter summaries and exercises; complete the following programming exercises: 1-8 in Chapter 6; 1-9 in Chapter 7; Watch Dr. Vierthaler’s videos: Episode 09: Dictionaries Episode 10: Putting it Together (Analyses) Episode 11: Errors (reading and handling) Note: the sequences are somewhat different in Zelle’s textbook and Vierthaler’s videos. I would recommend you to always check Vierthaler’s videos and also check videos which cover topics that you read about in Zelle’s book. Submitting homework: Homework assignment must be submitted by the beginning of the next class; Now, that you know how to use GitHub, you will be submitting your homework pushing it to github: Create a relevant subfoler in your HW070172 repository and place your HW files there; push them to your GitHub account; Email me the link to your repository with a short message (Something like: I have completed homework for Lesson 3, which is uploaded to my repository … in subfolder L03) In the subject of your email, please, add the following: CCXXXXX-LXX-HW-YourLastName-YourMatriculationNumber, where CCXXXXX is the numeric code of the course; LXX is the lesson for which the homework is being submitted; YourLastName is your last name, and YourMatriculationNumber is your matriculation number. "],["lesson-06-webscraping.html", "6 Lesson 06: Webscraping 6.1 Getting to Know WGET 6.2 Software 6.3 Class 6.4 Sample commands 6.5 A sidenote on issues in general 6.6 Practicing Scraping 6.7 Practice 1: very easy 6.8 Practice 2: easy-ish 6.9 Practice 3 (aka Homework): a tiny-bit tricky 6.10 Reference Materials 6.11 Homework 6.12 Submitting homework", " 6 Lesson 06: Webscraping 6.1 Getting to Know WGET Here we will discuss webscraping — the main process of efficiently collecting large volumes of information from the Internet. 6.2 Software wget (https://www.gnu.org/software/wget/), a free software package for retrieving files using HTTP, HTTPS, FTP and FTPS the most widely-used Internet protocols. It is a non-interactive command line tool, so it may easily be called from scripts, cron jobs, terminals without X-Windows support, etc. NB: on installing wget: On Windows (the easiest): download from https://eternallybored.org/misc/wget/ &gt; choose the latest 64-bit ZIP file (EXE will most likely be blocked by your browser as a potentially dangerous file). Unzip the file and copy wget.exe to the folder where you are planning to scrape data; NB: the easiest approach on Windows is to move/copy this file into relevant folders. On Mac (and, possibly, Linux): brew install wget 6.3 Class practical examples of working with wget single link download batch download web-page analysis extraction of links with regular expressions modification of links with regular expressions 6.4 Sample commands wget link wget -i file_with_links.txt wget -i file_with_links.txt -P ./folderYouWantToSaveTo/ -nc Where: -P is a folder parameter, which instructs wget where you want to store downloaded files (optional). -nc is a no-clobber parameter, which instructs wget to skips files, if they already exist (optional) Link examples: https://maximromanov.github.io/dh_in_mes/files/articles/1860-11-12_article_01.txt https://maximromanov.github.io/dh_in_mes/files/articles/1860-11-12_article_02.txt https://maximromanov.github.io/dh_in_mes/files/articles/1860-11-12_article_03.txt NB: there are many other parameters with which you can adjust wget to your needs. 6.4.1 Issues with WGET on Windows As we have run into a number of issues with trying to run WGET on Windows, here are some steps that will help to run it smoothly: first of all, WGET does not seem to play well with Powershell; it does work without any problems via Command Prompt (if your Windows “speaks” German, it is called Eingabeaufforderung; but if you search for Command Prompt, you should still be able to find it.). It also works without any issues via Git-Bash. The following steps will make it easier to use with both Command Prompt and Git-Bash. download the wget.exe file (from here: https://eternallybored.org/misc/wget/); copy/paste it into the C:\\Windows\\System32 folder (C:\\Windows\\System32 is a part of the so-called PATH — a series of paths which all Windows command line tools check); now, all the commands should be working as expected; NB: There is an alternative to WGET on Windows Powershell. Here is a detailed tutorial: https://adamtheautomator.com/powershell-download-file/. 6.4.2 Issues with WGET on Mac It may so happen that WGET will not work as intended with the homework assignment (specifically, you may not be able to download all the issues of Dispatch). From what I understand this is specifically a Mac issue. Last year the MacOS changed their main command line program from bash to zsh, and in some cases WGET may not work as intended under zsh. The solution is, luckily, rather simple: we just need to install bash and run WGET from bash. to install bash, run brew install bash; after that you can start bash by running bash on the command line; the prompt (the beginning of the command line where you type in your commands) should change into something like: bash-5.1$ now you can go to a folder where you want to save your downloaded results and run WGET; NB: you will need bash only for this step; after you restart the Terminal, you will be back to the default zsh (you can also run exit command to quit bash and return to zsh). 6.5 A sidenote on issues in general Keep in mind that one of the most important things that you need to learn in this course is that there are multiple solutions to most of the problems and tasks that you may face and the most common way to solve your problem is to break is down into smaller tasks (remember, there was a detailed discussion of this in Zelle’s book), and then look for efficient solutions to each step. No matter how advanced you are, “googling” will be the major way of finding suitable solutions. 6.6 Practicing Scraping The following sections give you some examples of links that you are most likely to encounter in real life. Your task is to figure out how to prepare lists of links (URLs) for downloading with WGET. Your first step will be to look under the hood of the current page, which you can do right clicking on the page and selecting something that looks like “View page source” (in Chrome or Edge) or “Show Page Source” (in Safari; you will need to enable “Show Develop menu in menu bar” in Preferences &gt; Advanced). Now, looking at the HTML code of the page you can find the actual URLs, which you can then extract from the HTML code with regular expressions (one thing you can do is to copy/paste the entire code of the page into a text editor that supports regular expressions—like Sublime Text). 6.7 Practice 1: very easy Article 01 Article 02 Article 03 Article 04 Article 05 Article 06 Article 07 Article 08 Article 09 Article 10 Article 11 Article 12 Article 13 Article 14 Article 15 6.8 Practice 2: easy-ish Article 16 Article 17 Article 18 Article 19 Article 20 Article 21 Article 22 Article 23 Article 24 Article 25 Article 26 Article 27 Article 28 Article 29 Article 30 Article 31 Article 32 Article 33 Article 34 Article 35 Article 36 Article 37 Article 38 Article 39 6.9 Practice 3 (aka Homework): a tiny-bit tricky download issues of “Richmond Times Dispatch” (Years 1860-1865, only!), which are available at: http://www.perseus.tufts.edu/hopper/collection?collection=Perseus:collection:RichTimes) 6.10 Reference Materials Milligan, Ian. 2012. “Automated Downloading with Wget.” Programming Historian, June. https://programminghistorian.org/lessons/automated-downloading-with-wget. Kurschinski, Kellen. 2013. “Applied Archival Downloading with Wget.” Programming Historian, September. https://programminghistorian.org/lessons/applied-archival-downloading-with-wget. Baxter, Richard. 2019. “How to download your website using WGET for Windows.” https://builtvisible.com/download-your-website-with-wget/. Alternatively, this operation can be done with a Python script: Turkel, William J., and Adam Crymble. 2012. “Downloading Web Pages with Python.” Programming Historian, July. https://programminghistorian.org/lessons/working-with-web-pages. 6.11 Homework Scraping the “Dispatch”: download issues of “Richmond Times Dispatch” (Years 1860-1865, only!), which are available at: http://www.perseus.tufts.edu/hopper/collection?collection=Perseus:collection:RichTimes) In a separate markdown file, describe your steps of how you completed this task (to be uloaded with the rest of your homework). Python Work through Chapters 8 and 11 of Zelle’s book; read chapters carefully; work through the chapter summaries and exercises; complete the following programming exercises: 1-8 in Chapter 8 and 1-11 in Chapter 11; Watch Dr. Vierthaler’s videos: Episode 12: Functions Episode 13: Libraries and NLTK Episode 14: Regular Expressions Note: the sequences are somewhat different in Zelle’s textbook and Vierthaler’s videos. I would recommend you to always check Vierthaler’s videos and also check videos which cover topics that you read about in Zelle’s book. 6.12 Submitting homework Homework assignment must be submitted by the beginning of the next class; Email your homework to the instructor. if your homework is to create a file, email it as an attachment if your homework is a blogpost on your website, email the link to your website and to the blogpost with your homework. In the subject of your email, please, add the following: 070112-LXX-HW-YourLastName-YourMatriculationNumber, where LXX is the lesson for which the homework is submitted, YourLastName is your last name, and YourMatriculationNumber is your matriculation number. "],["lesson-07-understanding-structured-data.html", "7 Lesson 07: Understanding Structured Data 7.1 Major Data Formats 7.2 Larger Examples 7.3 In-Class Practice (and homework) 7.4 Homework 7.5 Solution", " 7 Lesson 07: Understanding Structured Data 7.1 Major Data Formats Doing Digital Humanities practically always means working with structured data of some kind. In most general terms, structured data means some explicit annotation or classification that the machine can understand, and therefore — effectively use. When we see the word “Berlin”, we are likely to automatically assume that this is the name of the capital of Germany The machine cannot know that, unless there is something else in the data that allows it to figure it out (here, an XML tag): &lt;settlement country=\"Germany\" type=\"capital city\"&gt;Berlin&lt;/settlement&gt; — from this annotation (and its attributes) the machine can be instructed to interpret the string Berlin as a settlement of the type capital city in the country of Germany. It is important to understand most common data formats in order to be able to create and generate them as well as to convert between different formats. When we decide which format we want to work with, we need to consider the following: the ease of working with a given format (manual editing); suitability for specific analytic software; human-friendliness and readability; open vs. proprietary. In general, it does not make any sense to engage in the format wars (i.e., one format is better than another); one should rather develop an understanding that almost every format has its use and value in specific contexts or for specific tasks. What we also want is not to stick to a specific format and try to do everything with it and only it, but rather to be able to write scripts with which we can generate data in suitable formats or convert our data from one format into another. Let’s take a look at the same example in some of the most common formats. 7.1.1 XML (Extensible Markup Language) &lt;note&gt; &lt;to&gt;Tove&lt;/to&gt; &lt;from&gt;Jani&lt;/from&gt; &lt;heading&gt;Reminder&lt;/heading&gt; &lt;body&gt;Don’t forget me this weekend!&lt;/body&gt; &lt;/note&gt; 7.1.2 CSV/TSV (Comma-Separated Values/ Tab-Separated Values) to,from,heading,body Tove,Jani,Reminder,Don’t forget me this weekend! to,from,heading,body &quot;Tove&quot;,&quot;Jani&quot;,&quot;Reminder&quot;,&quot;Don’t forget me this weekend!&quot; 7.1.3 JSON (JavaScript Object Notation) { &quot;to&quot;: &quot;Tove&quot;, &quot;from&quot;: &quot;Jani&quot;, &quot;heading&quot;: &quot;Reminder&quot;, &quot;body&quot;: &quot;Don’t forget me this weekend!&quot; } 7.1.4 YML or YAML (Yet Another Markup Language &gt; YAML Ain’t Markup Language) to: Tove from: Jani heading: Reminder body: Don’t forget me this weekend 7.1.5 BibTeX: most common bibliographic format We have already used this format in our lesson on sustainable writing. If you take a closer look at the record below, you may see that this format contains lots of valuable information. Most of this we will need for our project. @incollection{LuhmannKommunikation1982, title = {Kommunikation mit Zettelkiisten}, booktitle = {Öffentliche Meinung und sozialer Wandel: Für Elisabeth Noelle-Neumann = Public opinion and social change}, author = {Luhmann, Niklas}, editor = {Baier, Horst and Noelle-Neumann, Elisabeth}, date = {1982}, pages = {222--228}, publisher = {{westdt. Verl}}, location = {{Opladen}}, annotation = {OCLC: 256417947}, file = {Absolute/Path/To/PDF/Luhmann 1982 - Kommunikation mit Zettelkiisten.pdf}, isbn = {978-3-531-11533-7}, langid = {german} } 7.2 Larger Examples In most cases, if you do data analysis, you will need formats that allow you to store multiple items. So, let’s take a look at some most commonly used options. (NB: In some cases, you may still want to opt for a format that stores a single item per file; this may be the case when single items are rather large and it may make sense to keep them as separate files, especially if you need to work more closely with each item — ready closely, annotate, edit, etc.) 7.2.1 CSV / TSV city,growth_from_2000_to_2013,latitude,longitude,population,rank,state New York,4.8%,40.7127837,-74.0059413,8405837,1,New York Los Angeles,4.8%,34.0522342,-118.2436849,3884307,2,California Chicago,-6.1%,41.8781136,-87.6297982,2718782,3,Illinois TSV is a better option than a CSV, since TAB characters are very unlikely to appear in values. Neither TSV not CSV are good for preserving new line characters (\\n)—or, in other words, text split into multiple lines. As a workaround, one can convert \\n into some unlikely-to-occur character combination (for example, ;;;), which would allow to restore \\n later , if necessary. 7.2.2 JSON [ { &quot;city&quot;: &quot;New York&quot;, &quot;growth_from_2000_to_2013&quot;: &quot;4.8%&quot;, &quot;latitude&quot;: 40.7127837, &quot;longitude&quot;: -74.0059413, &quot;population&quot;: &quot;8405837&quot;, &quot;rank&quot;: &quot;1&quot;, &quot;state&quot;: &quot;New York&quot; }, { &quot;city&quot;: &quot;Los Angeles&quot;, &quot;growth_from_2000_to_2013&quot;: &quot;4.8%&quot;, &quot;latitude&quot;: 34.0522342, &quot;longitude&quot;: -118.2436849, &quot;population&quot;: &quot;3884307&quot;, &quot;rank&quot;: &quot;2&quot;, &quot;state&quot;: &quot;California&quot; }, { &quot;city&quot;: &quot;Chicago&quot;, &quot;growth_from_2000_to_2013&quot;: &quot;-6.1%&quot;, &quot;latitude&quot;: 41.8781136, &quot;longitude&quot;: -87.6297982, &quot;population&quot;: &quot;2718782&quot;, &quot;rank&quot;: &quot;3&quot;, &quot;state&quot;: &quot;Illinois&quot; } ] 7.2.3 YML/YAML YAML is often used only for a single set of parameters. city: New York growth_from_2000_to_2013: 4.8% latitude: 40.7127837 longitude: -74.0059413 population: 8405837 rank: 1 state: New York But it can also be used for storage of serialized data. It has advantages of both JSON and CSV: the overall simplicity of the format (no tricky syntax) is similar to that of CSV/TSV, but it is more readable than CSV/TSV in any text editor, and is more difficult to break—again, due to the simplicity of the format. New York: growth_from_2000_to_2013: 4.8% latitude: 40.7127837 longitude: -74.0059413 population: 8405837 rank: 1 state: New York Los Angeles: growth_from_2000_to_2013: 4.8% latitude: 34.0522342 longitude: -118.2436849 population: 3884307 rank: 2 state: California Chicago: growth_from_2000_to_2013: -6.1% latitude: 41.8781136 longitude: -87.6297982 population: 2718782 rank: 3 state: Illinois YAML files can be read with Python into dictionaries like so: import yaml dictionary = yaml.load(open(pathToFile)) You will most likely need to install yaml library; it is also quite easy to write a script that would read such serialized data. (yaml module may not work on later versions of python.) 7.2.4 Installing libraries for python In general, it should be as easy as running the following command in your command line tool: pip install --upgrade libraryName pip is the standard package installer for python; if you are running version 3.xx of python, it may be pip3 instead of pip. If you have Anaconda installed, you can also use Anaconda interface to install packages; install is the command to install a package that you need; --upgrade is an optional argument that you would need only when you upgrade already installed package; libraryName is the name of the library that you want to install. This should work just fine, but sometimes it does not—usually when you have multiple versions of python installed and they may start conflicting with each other (another good reason to handle your python installations via Anaconda). There is, luckily, a workaround that seems to do the trick. You can modify your command in the following manner: python -m pip install --upgrade libraryName python here is whatever alias you are using for running python. If you are on Mac, python is installed with the original MacOS setup and python command remains reserved for the erlier versions of python (usually, 2.x). If you installde the latest version of python, it will be some 3.x version and the default command to run it on your Mac will be python3, so the full command will look: python3 -m pip install --upgrade libraryName) 7.3 In-Class Practice (and homework) Let’s try convert this csv file with geographical data on the medieval Islamic world into all the above discussed formats. This is a TSV file with the following structure: settlement_id languages names_ara_common names_ara_common_other names_eng_search names_eng_translit names_eng_translit_other region_URI source top_type coordinates QAHIRA_312E300N_S [&#39;ara&#39;, &#39;eng&#39;] القاهرة القاهرة Qahira, Cairo al-Qāhiraŧ al-Madīnaŧ al-Qāhiraŧ Misr_RE maximromanov metropoles [31.2357, 30.0444] IRBIL_440E361N_S [&#39;ara&#39;, &#39;eng&#39;] إربيل إربيل Irbil, Erbil Irbīl Irbīl Aqur_RE maximromanov towns [44.009085, 36.191231] DANIYA_001E388N_S [&#39;ara&#39;, &#39;eng&#39;] دانية دانية Daniya, Dénia Dāniyaŧ Dāniyaŧ Andalus_RE maximromanov towns [0.105056, 38.838799] WASHQA_003W421N_R [&#39;ara&#39;, &#39;eng&#39;] وشقة وشقة Washqa Wašqaŧ Wašqaŧ Andalus_RE cornuData regions [-0.35371, 42.16109] WASHQA_003W421N_S [&#39;ara&#39;, &#39;eng&#39;] وشقة وشقة Washqa Wašqaŧ Wašqaŧ Andalus_RE cornuData towns [-0.35371, 42.16109] BALANSIYYA_004W394N_R [&#39;ara&#39;, &#39;eng&#39;] بلنسية بلنسية Balansiyya Balansiyyaŧ Balansiyyaŧ Andalus_RE cornuData regions [-0.41486, 39.43516] BALANSIYYA_004W394N_S [&#39;ara&#39;, &#39;eng&#39;] بلنسية بلنسية Balansiyya Balansiyyaŧ Balansiyyaŧ Andalus_RE cornuData towns [-0.41486, 39.43516] SHAQR_004W391N_S [&#39;ara&#39;, &#39;eng&#39;] الشقر الشقر al-Shaqr al-Šaqr al-Šaqr Andalus_RE cornuData villages [-0.43734, 39.16483] QANT_004W383N_S [&#39;ara&#39;, &#39;eng&#39;] قانت قانت Qant Qānt Qānt Andalus_RE cornuData towns [-0.47061, 38.34618] You need to convert it into: XML (here, you will need to come up with an format for your XML; use the very first example given in the lesson as your template); CSV/TSV; JSON; YML; Suggestions: start with some pseudo code: what are the steps into which you can break this operation? using a dictionary may help a lot; for your solutions, you are welcome to look for “easy” ways to convert these files (like online converters that convert from one format into another) — add those into your solution. But you also need to write scripts that convert from one format into another. 7.4 Homework Finish the conversion task; Hint: loading the TSV file into a dictionary may be a good step to start with; upload your results together with scripts to your homework github repository; send me an email with a link to these files Python Make sure to finish the last assignment from Zelle’s book: work through Chapters 8 and 11 of Zelle’s book; read chapters carefully; work through the chapter summaries and exercises; complete the following programming exercises: 1-8 in Chapter 8 and 1-11 in Chapter 11; And watch Dr. Vierthaler’s videos, if you have not done that already: Episode 12: Functions Episode 13: Libraries and NLTK Episode 14: Regular Expressions Note: the sequences are somewhat different in Zelle’s textbook and Vierthaler’s videos. I would recommend you to always check Vierthaler’s videos and also check videos which cover topics that you read about in Zelle’s book. Submitting homework: Homework assignment must be submitted by the beginning of the next class; Now, that you know how to use GitHub, you will be submitting your homework pushing it to github: Create a relevant subfolder in your repository and place your HW files there; push them to your GitHub account; Email me the link to your repository with a short message (Something like: I have completed homework for Lesson 3, which is uploaded to my repository … in subfolder L03) 7.5 Solution Below is the solution to the homework: three functions that convert a TSV file into XML, YML, and JSON. Your solutions may be different, but they are considered correct as long as your results are what they must be. import csv import json # delim should be either &quot;\\t&quot; for TSV or &quot;,&quot; for CSV def converter_tsv_to_json(file, delim): with open(file) as f1: reader = csv.DictReader(f1, delimiter=delim) settlements = {} for row in reader: settlements[row[&quot;settlement_id&quot;]] = row with open(file.replace(&quot;.csv&quot;, &quot;.json&quot;), &quot;w&quot;) as f9: json.dump(settlements, f9, indent=4, ensure_ascii=False) def converter_tsv_to_yml(file): with open(file, &quot;r&quot;, encoding=&quot;utf8&quot;) as f1: data = f1.read().strip().split(&quot;\\n&quot;) header = data[0].split(&quot;\\t&quot;) allData = [] for d in data[1:]: temp = d.split(&quot;\\t&quot;) tempVar = [temp[0]+&quot;:&quot;] for i in range(0, len(header)): item = &quot;\\t%s: %s&quot; % (header[i], temp[i]) tempVar.append(item) tempVarFinal = &quot;\\n&quot;.join(tempVar) allData.append(tempVarFinal) ReallyFinalData = &quot;\\n\\n&quot;.join(allData) with open(file.replace(&quot;.csv&quot;, &quot;.yml&quot;), &quot;w&quot;, encoding=&quot;utf8&quot;) as f9: f9.write(ReallyFinalData) def converter_tsv_to_xml(file): with open(file) as f1: reader = csv.DictReader(f1, delimiter=&quot;\\t&quot;) data = [] for row in reader: temp = [] for k, v in row.items(): temp.append(&quot;&lt;%s&gt;%s&lt;/%s&gt;&quot; % (k, v, k)) tempComplete = &quot;&lt;settlement&gt;\\n\\t%s\\n&lt;/settlement&gt;&quot; % &quot;\\n\\t&quot;.join( temp) data.append(tempComplete) ReallyFinalData = &quot;\\n\\n&quot;.join(data) with open(file.replace(&quot;.csv&quot;, &quot;.xml&quot;), &quot;w&quot;, encoding=&quot;utf8&quot;) as f9: f9.write(ReallyFinalData) converter_tsv_to_json(&quot;settlements.csv&quot;, &quot;\\t&quot;) converter_tsv_to_yml(&quot;settlements.csv&quot;) converter_tsv_to_xml(&quot;settlements.csv&quot;) "],["lesson-08-converting-the-dispatch.html", "8 Lesson 08: Converting the Dispatch 8.1 Original XML files analysis 8.2 Convert to a cleaner format 8.3 In-Class Practice (and homework) 8.4 Homework 8.5 Solution", " 8 Lesson 08: Converting the Dispatch 8.1 Original XML files analysis analyze structure and identify main structural elements; extract main structural units (articles); extract and generate additional metadata elements: date; article ID; header/title; texts. 8.2 Convert to a cleaner format what format would be best for this kind of data? (no single correct answer; any answer must be substantiated); possible formats: a simple XML; JSON; YML; CSV / TSV; other formats. 8.3 In-Class Practice (and homework) Let’s start working on the conversion of our initial data into other formats. (Suggestion: start with some pseudo code: what are the steps into which you can break this operation?) 8.4 Homework Finish the conversion task; Annotate your script (i.e., add comment to every line of code describing what is happenning there); Submitting homework: Homework assignment must be submitted by the beginning of the next class; Now, that you know how to use GitHub, you will be submitting your homework pushing it to github: Create a relevant subfolder in your repository and place your HW files there; push them to your GitHub account; Email me the link to your repository with a short message (Something like: I have completed homework for Lesson 3, which is uploaded to my repository … in subfolder L03) 8.5 Solution Below is the solution to the homework: all issues of the Dispatch (stored in ./Dispatch/) are converted into YML and saved into a different folder (./Dispatch_Processed/). import re import os source = &quot;./Dispatch/&quot; target = &quot;./Dispatch_Processed/&quot; # needs to be created beforehand! lof = os.listdir(source) counter = 0 # general counter to keep track of the progress for f in lof: if f.startswith(&quot;dltext&quot;): # fileName test newF = f.split(&quot;:&quot;)[-1] + &quot;.yml&quot; # in fact, yml-like issueVar = [] with open(source + f, &quot;r&quot;, encoding=&quot;utf8&quot;) as f1: text = f1.read() date = re.search(r&#39;&lt;date value=&quot;([\\d-]+)&quot;&#39;, text).group(1) split = re.split(&quot;&lt;div3 &quot;, text) for s in split[1:]: s = &quot;&lt;div3 &quot; + s # a step to restore the integrity of each item try: unitType = re.search(r&#39;type=&quot;([^\\&quot;]+)&quot;&#39;, s).group(1) except: unitType = &quot;noType&quot; try: header = re.search(r&#39;&lt;head.*&lt;/head&gt;&#39;, s).group(0) header = re.sub(&quot;&lt;[^&lt;]+&gt;&quot;, &quot;&quot;, header) except: header = &quot;NO HEADER&quot; text = s text = re.sub(&quot;&lt;[^&lt;]+&gt;&quot;, &quot; &quot;, text) text = re.sub(&quot; +\\n|\\n +&quot;, &quot;\\n&quot;, text) text = text.strip() text = re.sub(&quot;\\n+&quot;, &quot;;;; &quot;, text) text = re.sub(&quot; +&quot;, &quot; &quot;, text) text = re.sub(r&quot; ([\\.,:;!])&quot;, r&quot;\\1&quot;, text) itemID = &quot;ID: &quot; + date + &quot;_&quot; + unitType + &quot;_%03d&quot; % c if len(re.sub(&quot;\\W+&quot;, &quot;&quot;, text)) != 0: dateVar = &quot;DATE: &quot; + date unitType = &quot;TYPE: &quot; + unitType header = &quot;HEADER: &quot; + header # @§@ is used to replace &quot;:&quot;, because in YML : is used # as a divider between the key and value text = &quot;TEXT: &quot; + text.replace(&quot;:&quot;, &quot;@§@&quot;) + &quot;\\n\\n&quot; var = &quot;\\n&quot;.join([itemID, dateVar, unitType, header, text]) issueVar.append(var) issueNew = &quot;&quot;.join(issueVar) with open(target + newF, &quot;w&quot;, encoding=&quot;utf8&quot;) as f9: f9.write(issueNew) counter += 1 if counter % 100 == 0: print(counter) "],["lesson-09-extracting-tagged-data-for-analysis.html", "9 Lesson 09: Extracting Tagged Data for Analysis 9.1 Concept of tidy data 9.2 Extracting tagged entities 9.3 Homework 9.4 Solution", " 9 Lesson 09: Extracting Tagged Data for Analysis 9.1 Concept of tidy data Each variable is in its own column Each observation is in its own row Each value is in its own cell (NB: Additionally, data must be normalized, i.e. values in the same columns must be in the same format: if length, all in inches or centimeters; if weight, all in pounds or kilos; etc. It does not matter what units are used; the important part is that the same units are used throughout.) Source: Wickham, Hadley, and Garrett Grolemund. 2017. R for Data Science: Import, Tidy, Transform, Visualize, and Model Data. Sebastopol, CA: O’Reilly UK Ltd. https://r4ds.had.co.nz/; for a Chapter on tidy data, see: https://r4ds.had.co.nz/tidy-data.html. 9.2 Extracting tagged entities Why? We can analyze tagged entities as they feature across time and space in the coverage of the Dispatch (again, for all intents and purposes, we can use this newspaper as an equivalent of a chronicle, or even broader, as that of a chronological corpus.) How? Different types of entities are already tagged in the text and we can use this tagging to make abstractions of each article. These abstractions is what we will then use in our initial simple analysis. In order to extract tagged data, we first need to understand what we can extract. This can be done by creating a frequency list of all XML tags used in the issues of the Dispatch. These results will help us to understand what kind of data we can use for analysis. The following script counts all the tags and saves results into a TSV format organized from the most frequent to the least frequent. import re import os source = &quot;./Dispatch/&quot; target = &quot;./Dispatch_Processed/&quot; # needs to be created beforehand! lof = os.listdir(source) resDic = {} for f in lof: if f.startswith(&quot;dltext&quot;): # fileName test newF = f.split(&quot;:&quot;)[-1] + &quot;.yml&quot; # in fact, yml-like # collect and count all XML tags issueVar = [] c = 0 # technical counter with open(source + f, &quot;r&quot;, encoding=&quot;utf8&quot;) as f1: text = f1.read() for i in re.findall(r&quot;(&lt;\\w+)&quot;, text): # print(i) if i in resDic: resDic[i] += 1 else: resDic[i] = 1 final = [] for k, v in resDic.items(): value = &quot;%010d\\t%s&quot; % (v, k) final.append(value) # input(value) sortedResults = sorted(final, reverse=True) finalResults = &quot;\\n&quot;.join(sortedResults) with open(&quot;tag_results.csv&quot;, &quot;w&quot;, encoding=&quot;utf8&quot;) as f9: f9.write(finalResults) print(&quot;Done!&quot;) The results will look in the following manner (with some ommissions to save space): 0000907398 &lt;milestone 0000649103 &lt;p 0000552453 &lt;persName 0000526235 &lt;surname 0000446296 &lt;head 0000402419 &lt;placeName 0000370390 &lt;num 0000353521 &lt;rs 0000342807 &lt;div3 0000325316 &lt;foreName 0000197514 &lt;roleName 0000170166 &lt;measure 0000164988 &lt;orgName 0000106719 &lt;hi ... 0000017332 &lt;div1 0000015210 &lt;cit 0000013816 &lt;opener ... 0000002571 &lt;table 0000002445 &lt;sic 0000002278 &lt;language ... 0000001349 &lt;text 0000001349 &lt;teiHeader 0000001349 &lt;taxonomy ... 0000000016 &lt;dateRange 0000000013 &lt;div6 0000000001 &lt;div7 These results suggest that the following tags can be useful, as they have high frequencies and carry meaningful data: &lt;persName&gt; (552,453); &lt;placeName&gt; (402,419); &lt;orgName&gt; (164,988); (&lt;rs&gt; is another frequent tag with potentially valuable information (353,521). These tagged entities, however, lack additional metadata, which will make their analysis more complicated, so we will skip it. On the &lt;rs&gt; tag see &lt;/https://tei-c.org/release/doc/tei-p5-doc/en/html/ref-rs.html/&gt;.) Next step will be to understand the structure of these selected tags and process them accordingly, aggregating results into a tidy format. We can build on the script from the previous lesson, to which we will need to add some modifications. This is your homework :) Our tidy results should look similar to what you see below: articleID date itemType itemUnified itemId 1864-04-28_article_002 1864-04-28 placename plymouth, washington, north carolina tgn,2076159 1864-04-28_article_002 1864-04-28 placename plymouth, washington, north carolina tgn,2076159 1864-04-28_article_002 1864-04-28 persname wessels,brigadier-general,,,, wessels,h.,w. 1864-04-28_article_002 1864-04-28 persname lincoln,,,,, lincoln 1864-04-28_article_002 1864-04-28 placename plymouth, washington, north carolina tgn,2076159 1864-04-28_article_002 1864-04-28 persname moffitt,colonel,,,, moffitt 1864-04-28_article_002 1864-04-28 placename plymouth, washington, north carolina tgn,2076159 1864-04-28_article_002 1864-04-28 orgname free school school 1864-04-28_article_002 1864-04-28 orgname episcopal church church 1864-04-28_article_002 1864-04-28 persname moffitt,lieutenant-colonel,,,, moffitt 1864-04-28_article_002 1864-04-28 persname wessels,brigadier-general,h.,w.,, wessels,h.,w. 1864-04-28_article_002 1864-04-28 persname stewart,,andrew,,, stewart,andrew 1864-04-28_article_002 1864-04-28 placename plymouth, washington, north carolina tgn,2076159 1864-04-28_article_002 1864-04-28 orgname provost guard guard 1864-04-28_article_002 1864-04-28 persname wessels,brigadier-general,h.,w.,, wessels,h.,w. 1864-04-28_article_002 1864-04-28 persname beegle,,d.,f.,, beegle,d.,f. 1864-04-28_article_002 1864-04-28 placename plymouth, washington, north carolina tgn,2076159 The structure of this data is as follows: articleID is the ID of each article; date is the date when the article was published (the same date effectively refers to the same issue); itemType, itemUnified, itemId: these following three columns represent each tagged entity. In most cases each entity can be described with a single or multiple variables. A single variable can be used when it represents some kind of unique identifier from some external database/databank. such unique identifiers can be used to collect additional information on our entities from these external databases/databanks. For example, for &lt;placeName&gt; entities it could be enough to use the key= attribute which contains unique identifiers (for example, tgn,2111971) from the Getty Thesaurus of Geographical Names (http://tgndownloads.getty.edu/default.aspx). Unfortunately, such data is not available more often than it is. I decided to use the following three elements (ideally trying to preserve (1) the type of an entity (itemType), (2) how it appears in the text (skipped), (3) its unified/normalized form (itemUnified, not available for all types); and (4) its unique identifier (itemId, also not available for all types)). 9.3 Homework Finish the assigned task; Annotate your script (i.e., add comment to every line of code describing what is happenning there); Submitting homework: Homework assignment must be submitted by the beginning of the next class; Now, that you know how to use GitHub, you will be submitting your homework pushing it to github: Create a relevant subfolder in your repository and place your HW files there; push them to your GitHub account; Email me the link to your repository with a short message (Something like: I have completed homework for Lesson 3, which is uploaded to my repository … in subfolder L03) 9.4 Solution Below is the solution to the homework: all issues of the Dispatch (stored in ./Dispatch/) are converted into YML and saved into a different folder (./Dispatch_Processed/). This is essentially the script from the previous lesson, to which additional lines of code have been added (after # NEW PART). import re import os source = &quot;./Dispatch/&quot; target = &quot;./Dispatch_Processed/&quot; # needs to be created beforehand! lof = os.listdir(source) counter = 0 # general counter to keep track of the progress entities = [] # we will collect all extracted data here for f in lof: if f.startswith(&quot;dltext&quot;): # fileName test newF = f.split(&quot;:&quot;)[-1] + &quot;.yml&quot; # in fact, yml-like issueVar = [] c = 0 # technical counter with open(source + f, &quot;r&quot;, encoding=&quot;utf8&quot;) as f1: text = f1.read() date = re.search(r&#39;&lt;date value=&quot;([\\d-]+)&quot;&#39;, text).group(1) split = re.split(&quot;&lt;div3 &quot;, text) for s in split[1:]: c += 1 s = &quot;&lt;div3 &quot; + s # a step to restore the integrity of items try: unitType = re.search(r&#39;type=&quot;([^\\&quot;]+)&quot;&#39;, s).group(1) except: unitType = &quot;noType&quot; try: header = re.search(r&#39;&lt;head.*&lt;/head&gt;&#39;, s).group(0) header = re.sub(&quot;&lt;[^&lt;]+&gt;&quot;, &quot;&quot;, header) except: header = &quot;NO HEADER&quot; text = s text = re.sub(&quot;&lt;[^&lt;]+&gt;&quot;, &quot; &quot;, text) text = re.sub(&quot; +\\n|\\n +&quot;, &quot;\\n&quot;, text) text = text.strip() text = re.sub(&quot;\\n+&quot;, &quot;;;; &quot;, text) text = re.sub(&quot; +&quot;, &quot; &quot;, text) text = re.sub(r&quot; ([\\.,:;!])&quot;, r&quot;\\1&quot;, text) itemID = date + &quot;_&quot; + unitType + &quot;_%03d&quot; % c if len(re.sub(&quot;\\W+&quot;, &quot;&quot;, text)) != 0: itemIdvar = &quot;ID: &quot; + itemID dateVar = &quot;DATE: &quot; + date unitType = &quot;TYPE: &quot; + unitType header = &quot;HEADER: &quot; + header # @§@ is used to replace &quot;:&quot;, because in YML : is used as a divider between the key and value text = &quot;TEXT: &quot; + text.replace(&quot;:&quot;, &quot;@§@&quot;) + &quot;\\n\\n&quot; var = &quot;\\n&quot;.join( [itemIdvar, dateVar, unitType, header, text]) issueVar.append(var) # NOW, WE CAN ADD SOME CODE TO PROCESS EACH ITEM AND COLLECT ALL INTO OUR TIDY DATA FORMAT # STRUCTURE: itemID, dateVar, EXTRACTED_ITEM (type, unified_form, id) # ADDING TO: entities (list) for i in re.findall(r&quot;(&lt;\\w+[^&gt;]+&gt;)&quot;, s): if &quot;persName&quot; in i and &quot;authname&quot; in i and &quot;n=&quot; in i: # input(i) itemType = &quot;persName&quot; itemUnified = re.search(r&#39;n=&quot;([^&quot;]+)&quot;&#39;, i).group(1) itemId = re.search( r&#39;authname=&quot;([^&quot;]+)&quot;&#39;, i).group(1) tempVar = &quot;\\t&quot;.join( [itemID, date, itemType, itemUnified, itemId]) entities.append(tempVar) elif &quot;placeName&quot; in i and &quot;authname&quot; in i and &quot;reg=&quot; in i: # input(i) itemType = &quot;placeName&quot; itemUnified = re.search( r&#39;reg=&quot;([^&quot;]*)&quot;&#39;, i).group(1) itemId = re.search( r&#39;authname=&quot;([^&quot;]+)&quot;&#39;, i).group(1) tempVar = &quot;\\t&quot;.join( [itemID, date, itemType, itemUnified, itemId]) entities.append(tempVar) elif &quot;orgName&quot; in i and &quot;type&quot; in i and &quot;n=&quot; in i: # print(i) itemType = &quot;orgName&quot; itemUnified = re.search(r&#39;n=&quot;([^&quot;]+)&quot;&#39;, i).group(1) itemId = re.search( r&#39;type=&quot;([^&quot;]+)&quot;&#39;, i).group(1) tempVar = &quot;\\t&quot;.join( [itemID, date, itemType, itemUnified, itemId]) entities.append(tempVar) else: pass issueNew = &quot;&quot;.join(issueVar) with open(target + newF, &quot;w&quot;, encoding=&quot;utf8&quot;) as f9: f9.write(issueNew) # count processed issues and print progress counter at every 100 counter += 1 # counter = counter + 1 # if counter is divisible by 100 (i.e., no remainder), then print it if counter % 100 == 0: print(counter) header = &quot;\\t&quot;.join([&quot;articleID&quot;, &quot;date&quot;, &quot;itemType&quot;, &quot;itemUnified&quot;, &quot;itemID&quot;]) entitiesFinal = header + &quot;\\n&quot; + &quot;\\n&quot;.join(entities).lower() with open(&quot;entities.csv&quot;, &quot;w&quot;, encoding=&quot;utf8&quot;) as f9: f9.write(entitiesFinal) print(&quot;Done!&quot;) "],["lesson-10-graphing-chronological-distribution-of-tagged-entities.html", "10 Lesson 10: Graphing Chronological Distribution of Tagged Entities 10.1 Abstractions of Newspaper Articles 10.2 Code: Line Graph 10.3 Missing Zeros Problem 10.4 Jupyter Notebook 10.5 Homework 10.6 Solution", " 10 Lesson 10: Graphing Chronological Distribution of Tagged Entities 10.1 Abstractions of Newspaper Articles In the previous lesson we created abstractions of our newspaper articles. Namely, we reduced the text in natural languages to mentions of places, persons, and organizations. Together, they give us an idea of the main actors (persons and organizations), i.e. who is involved in some developments described in each article, and main locations (placenames) of where these developments took place. ID: 1864-04-28_article_002 DATE: 1864-04-28 TYPE: article HEADER: Yankee rule in Plymouth. TEXT: Yankee rule in Plymouth.&lt;br&gt; The following orders are copies of hand-bills posted in the town of Plymouth.&lt;br&gt; It will be seen that Brig. Gen. Wessels is a model after Lincoln &#39;s own heart, and undertook to &quot;run the churches&quot; and the schools besides.&lt;br&gt; As we find the names of the General and the Provost Marshal, and the A. A., G.&#39;s on the register of the Libby Hotel, in this city, it is more than likely that the children &quot;between eight and fourteen&quot; in Plymouth are having a cheerful vacation, and that Col. Moffitt will refrain for the present from the disagreeable duty of reporting the derelict heads of families who don&#39;t enforce their attendance.&lt;br&gt; This is the school order&lt;br&gt; Notice.&lt;br&gt; The inhabitants of Plymouth are hereby notified that a Free school, for white children, will be spend under competent teachers,&lt;br&gt; On Monday, 18th inst,&lt;br&gt; in the Episcopal Church.&lt;br&gt; The attention of parents and guardians is called in this important subject; and it is expected that all children between eight and fourteen years of age will attend the school.&lt;br&gt; Those over fourteen may attend if they wish.&lt;br&gt; Lieut. Col. Moffitt, Provost Marshal, will institute careful inquiries, and report such families as neglect to avail themselves of the advantages thus offered. By command of Brig. Gen. H. W. Wessels, Andrew Stewart, Assistant Adjutant General. Plymouth, N. C., April 14th, 1864.&lt;br&gt; And this is the order for running the churches&lt;br&gt; Notice&lt;br&gt; Until further orders church call will be sounded at the Provost Guard on Sundays, at fifteen minutes before 11 A. M., and at 2.15 P. M. the call to be repeated promptly by the drums of the several regiments and detachments.&lt;br&gt; The annoyance caused by entering and leaving the churches during the performance of Divine service, and by the practice of spitting on the floor is excessive, and it is hoped that these evils will be corrected without the necessity of individual reproof. By order of Brig. Gen. H. W. Wessels, D. F. Beegle, Lieut, A. D. C. &amp; A. A. A. G. Plymouth, N. C, April 11th, 1864. Thus, the article above (1864-04-28_article_002) can be abstracted to the following data (here, based exclusively on entities already tagged in the initial XML documents): articleID date itemType itemUnified itemId 1864-04-28_article_002 1864-04-28 placename plymouth, washington, north carolina tgn,2076159 1864-04-28_article_002 1864-04-28 placename plymouth, washington, north carolina tgn,2076159 1864-04-28_article_002 1864-04-28 persname wessels,brigadier-general,,,, wessels,h.,w. 1864-04-28_article_002 1864-04-28 persname lincoln,,,,, lincoln 1864-04-28_article_002 1864-04-28 placename plymouth, washington, north carolina tgn,2076159 1864-04-28_article_002 1864-04-28 persname moffitt,colonel,,,, moffitt 1864-04-28_article_002 1864-04-28 placename plymouth, washington, north carolina tgn,2076159 1864-04-28_article_002 1864-04-28 orgname free school school 1864-04-28_article_002 1864-04-28 orgname episcopal church church 1864-04-28_article_002 1864-04-28 persname moffitt,lieutenant-colonel,,,, moffitt 1864-04-28_article_002 1864-04-28 persname wessels,brigadier-general,h.,w.,, wessels,h.,w. 1864-04-28_article_002 1864-04-28 persname stewart,,andrew,,, stewart,andrew 1864-04-28_article_002 1864-04-28 placename plymouth, washington, north carolina tgn,2076159 1864-04-28_article_002 1864-04-28 orgname provost guard guard 1864-04-28_article_002 1864-04-28 persname wessels,brigadier-general,h.,w.,, wessels,h.,w. 1864-04-28_article_002 1864-04-28 persname beegle,,d.,f.,, beegle,d.,f. 1864-04-28_article_002 1864-04-28 placename plymouth, washington, north carolina tgn,2076159 Such abstractions can never fully replace the close reading of text, but they open up possibilities of distant reading of the entire corpus of our newspaper. For example, we can measure the frequencies of mentions of specific entities over time in order to assess their prominence and importance across the entire period as well as to identify specific moments in time, when they (people, places, organizations/institutions) soared to some level of importance. Additionally, we can also assess how traditional reading can be reinforces or informed by distant reading. Let’s now take a look at a couple of simple examples. (After which we will take a look at the code and you will get an assignment to modify it.) Example 1: General Sherman and the burning of Atlanta William Tecumseh Sherman was a Union General serving under the command of Ulysses Grant during the Civil War. He is most known for his campaign through Georgia and the Carolinas in 1864 where he followed a scorched earth policy including the capture and burning of Atlanta. During the Grant Presidency, Sherman became Commanding General of the Army, formulating the military response to the conflict with Indian tribes in the west. Source: Lloyd Sealy Library — Key Personolities of the Civil War The two graphs below show mentions of both sherman and atlanta in the Dispatch issues: there we can see/show how the prominence of William Sherman went up in the course of his campaign in 1864, while the spike in mentions of Atlanta must reflect the capture and burning of the city. Example 2. The Battle of Shiloh (April 6–7, 1862) The Battle of Shiloh (also known as the Battle of Pittsburg Landing) was an early battle in the Western Theater of the American Civil War, fought April 6–7, 1862, in southwestern Tennessee. The Union Army of the Tennessee (Major General Ulysses S. Grant) had moved via the Tennessee River deep into Tennessee and was encamped principally at Pittsburg Landing on the west bank of the Tennessee River, where the Confederate Army of Mississippi (General Albert Sidney Johnston, P. G. T. Beauregard second-in-command) launched a surprise attack on Grant’s army from its base in Corinth, Mississippi. Johnston was mortally wounded during the fighting; Beauregard took command of the army and decided against pressing the attack late in the evening. Overnight, Grant was reinforced by one of his divisions stationed farther north and was joined by three divisions from the Army of the Ohio (Maj. Gen. Don Carlos Buell). The Union forces began an unexpected counterattack the next morning which reversed the Confederate gains of the previous day. On April 6, the first day of the battle, the Confederates struck with the intention of driving the Union defenders away from the river and into the swamps of Owl Creek to the west. Johnston hoped to defeat Grant’s army before the anticipated arrival of Buell and the Army of the Ohio. The Confederate battle lines became confused during the fighting, and Grant’s men instead fell back to the northeast, in the direction of Pittsburg Landing. A Union position on a slightly sunken road, nicknamed the “Hornet’s Nest” and defended by the divisions of Brig. Gens. Benjamin Prentiss and William H. L. Wallace, provided time for the remainder of the Union line to stabilize under the protection of numerous artillery batteries. Wallace was mortally wounded when the position collapsed, while several regiments from the two divisions were eventually surrounded and surrendered. Johnston was shot in the leg and bled to death while leading an attack. Beauregard acknowledged how tired the army was from the day’s exertions, and decided against assaulting the final Union position that night. Tired but unfought and well-organized men from Buell’s army and a division of Grant’s army arrived in the evening of April 6 and helped turn the tide the next morning, when the Union commanders launched a counterattack along the entire line. Confederate forces were forced to retreat, ending their hopes of blocking the Union advance into northern Mississippi. Though victorious, the Union army had suffered heavier casualties than the Confederates, and Grant was heavily criticized in the media for being taken by surprise. The Battle of Shiloh was the bloodiest engagement of the Civil War up to that point, with nearly twice as many casualties as the previous major battles of the war combined. Source: https://en.wikipedia.org/wiki/Battle_of_Shiloh. Now, let’s take a look at the graphs for the names highlighted in bold above: The battle of Shiloh is considered one of the bloodiest engagements of the Civil War. If we look at the mentions of deserter(s), killed, and wounded, we discover the most significant spike of all these terms soon after the battle. 10.2 Code: Line Graph import re import pandas import matplotlib.pyplot as plt template = &quot;&quot;&quot;&gt; Plotting data: %s&quot;&quot;&quot; # load entities data df = pandas.read_csv(&quot;entities.csv&quot;, sep=&quot;\\t&quot;, header=0) print(df) def searchDispatchData(searchTerm, fileName=&quot;fromTagged&quot;): print(template % (searchTerm)) # processing our data df[&quot;month&quot;] = [re.sub(&quot;-\\d\\d$&quot;, &quot;-01&quot;, str(i)) for i in df[&quot;date&quot;]] df[&quot;month&quot;] = pandas.to_datetime(df[&quot;month&quot;], format=&quot;%Y-%m-%d&quot;) # create zeros : two columns &quot;month&quot; and &quot;searchTerm&quot; (where all values are zeros) dfZeros = df[[&quot;month&quot;]] dfZeros = dfZeros.reset_index() dfZeros[searchTerm] = 0 dfZeros = dfZeros.drop_duplicates() # create a new table only with values that we want dfTemp = df[df.itemUnified.str.contains(searchTerm, na=False)] dfTemp = dfTemp[[&quot;month&quot;, &quot;itemType&quot;]] dfTemp = dfTemp.groupby([&quot;month&quot;]).count() dfTemp = dfTemp.reset_index() dfTemp[searchTerm] = dfTemp[&quot;itemType&quot;] dfTemp = dfTemp[[&quot;month&quot;, searchTerm]] # merge with dfZeros (reason: we need explicit 0 values for dates when our search term is not found # otherwise the graph will be misleading as the line on the graph will be connecting only dates with # frequencies more than zero) dfTemp = dfTemp.append(dfZeros, ignore_index=True) dfTemp = dfTemp.groupby([&quot;month&quot;]).sum() dfTemp = dfTemp.sort_values(by=&quot;month&quot;) dfTemp = dfTemp.reset_index() # plotting the results plt.rcParams[&quot;figure.figsize&quot;] = (20, 9) dfTemp.plot(x=&#39;month&#39;, y=searchTerm, legend=True, color=&#39;blue&#39;) plt.ylabel(&quot;absolute frequencies&quot;) plt.xlabel(&quot;dates (issues aggregated into months)&quot;) plt.title(&quot;entities with \\&quot;%s\\&quot; in them&quot; % (searchTerm)) plt.gca().yaxis.grid(linestyle=&#39;:&#39;) # the following line will simply open a pop-up with the graph # plt.show() # the following line will save the graph into a file fileNameToSave = &quot;plot1_%s_%s.png&quot; % (fileName, searchTerm) plt.savefig(fileNameToSave, dpi=300, bbox_inches=&quot;tight&quot;) plt.close(&quot;all&quot;) searchDispatchData(&quot;shiloh&quot;, &quot;shiloh&quot;) 10.3 Missing Zeros Problem Compare the following two graphs. The first one is “with zeros” and the second one “without zeros”. In the second graph we simply “collected” all mentions of Shiloh and plotted them with a line graph. The problem is that we have no explicit data on dates when Shiloh is not mentioned and, as a result, the graph suggests that Shiloh is mentioned quite a lot in the course of the year 1861. If we look at the first graph—where we have data for all the dates and each date when Shiloh is not mentioned has a value 0—we can see that Shiloh is mentioned only a couple of times in 1861 and then there is a huge spike of mentions in 1862, when the Battle of Shiloh took place. The main takeaway from this is that you should always be mindful of how you are filtering your data and what strategies you use for plotting it. Line graph can make a false suggestion, when some x-values are missing. A more reliable graph in such cases would be a “lollipop” graph that is shown below — lollipop graphs do not connect observations, and due to that they clearly show gaps in data. ## Code: Lollipop Graph import re import pandas import matplotlib.pyplot as plt template = &quot;&quot;&quot;&gt; Plotting data: %s&quot;&quot;&quot; # load entities data df = pandas.read_csv(&quot;entities.csv&quot;, sep=&quot;\\t&quot;, header=0) print(df) def searchDispatchData(searchTerm, fileName=&quot;fromTagged&quot;): print(template % (searchTerm)) # processing our data df[&quot;month&quot;] = [re.sub(&quot;-\\d\\d$&quot;, &quot;-01&quot;, str(i)) for i in df[&quot;date&quot;]] df[&quot;month&quot;] = pandas.to_datetime(df[&quot;month&quot;], format=&quot;%Y-%m-%d&quot;) # create a new table only with values that we want dfTemp = df[df.itemUnified.str.contains(searchTerm, na=False)] dfTemp = dfTemp[[&quot;month&quot;, &quot;itemType&quot;]] dfTemp = dfTemp.groupby([&quot;month&quot;]).count() dfTemp = dfTemp.reset_index() dfTemp[searchTerm] = dfTemp[&quot;itemType&quot;] dfTemp = dfTemp[[&quot;month&quot;, searchTerm]] # plotting the results - lollipop plt.rcParams[&quot;figure.figsize&quot;] = (20, 9) plt.stem(dfTemp[&#39;month&#39;], dfTemp[searchTerm]) plt.ylabel(&quot;absolute frequencies&quot;) plt.xlabel(&quot;dates (issues aggregated into months)&quot;) plt.title(&quot;entities with \\&quot;%s\\&quot; in them&quot; % (searchTerm)) plt.gca().yaxis.grid(linestyle=&#39;:&#39;) # the following line will save the graph into a file fileNameToSave = &quot;plot1_lollipop_%s_%s.png&quot; % (fileName, searchTerm) plt.savefig(fileNameToSave, dpi=300, bbox_inches=&quot;tight&quot;) plt.close(&quot;all&quot;) searchDispatchData(&quot;shiloh&quot;, &quot;shiloh&quot;) 10.4 Jupyter Notebook Jupyter Notebook (https://jupyter.org/) is a web application for creating and sharing computational documents. It is a very popular way of writing analytical code in Python. It allows one to write and execute code right in your browser, to combine code with regular prose, ans, also, execute written code section by section (or, more correctly, cell by cell — using the Jupyter lingo) — which in some cases has a lot of advantages. Jupyter Notebook can be installed in the manner that you are already familiar with: python -m pip install notebook (or: python3 -m pip install notebook) It can be then opened by running the following command in the command line tool of your choice (you should be in your working directory; make sure to restart your command line tool after installation): jupyter notebook After the Jupyter Notebook starts, you will be taken to your default browser and the first page of the Jupyter interface should show you the contents of the folder from which you started it. Something like this: You can download this already prepared notebook, which should look like this when you open it: 10.5 Homework Rewrite the code in such a way that would allow you to graph any kind of words or phrases in a similar manner (“The Losses at War” graph is generated in this manner).; Annotate your script (i.e., add comment to every line of code describing what is happening there); Submitting homework: Homework assignment must be submitted by the beginning of the next class; Now, that you know how to use GitHub, you will be submitting your homework pushing it to github: Create a relevant subfolder in your repository and place your HW files there; push them to your GitHub account; Email me the link to your repository with a short message (Something like: I have completed homework for Lesson 3, which is uploaded to my repository … in subfolder L03) 10.6 Solution The solution will be posted here later… "],["lesson-11-mapping-data-using-tagged-data.html", "11 Lesson 11: Mapping Data (using tagged data) 11.1 Preparing and Modeling Geospatial Data 11.2 Homework 11.3 Solution", " 11 Lesson 11: Mapping Data (using tagged data) 11.1 Preparing and Modeling Geospatial Data In a similar manner we can also graph geographical data — in combination with the temporary dimension. For this, however, we need to think through what kind of insight we can possibly get from geospatial data and how it should be prepared for mapping. Let’s start with a simple task: we will map the geospatial data from one of the previous lessons: settlements from the al-Thurayya Gazetteer. Below is the code that produces an interactive map. (Note: it is possible to use matplotlib for mapping, but installation of needed components has become rather complicated recently, so we will proceed with a different library: plotly) import plotly.express as px import pandas as pd althurayyaFile = &quot;settlements.csv&quot; df = pd.read_csv(althurayyaFile, sep=&quot;\\t&quot;, header=0) print(df) fig = px.scatter_geo(df, lon=&#39;lon&#39;, lat=&#39;lat&#39;, color=&quot;region_URI&quot;, hover_name=&quot;names_eng_translit&quot;, size=df[&quot;top_size&quot;]*df[&quot;top_size&quot;], projection=&quot;natural earth&quot;, fitbounds=&#39;locations&#39;) fig.update_layout( title_text=&#39;Provinces of the classical Islamic World (IX-Xthe centuries CE)&lt;br&gt;(Click legend to toggle provinces)&#39;, showlegend=True, geo=dict( scope=&#39;world&#39;, landcolor=&#39;rgb(250, 250, 250)&#39;, ) ) fig.show() # the following line will save the graph into an html file fig.write_html(&quot;althurayya.html&quot;) We can get the following map (for an intereactive map, try this link): Now, let’s get back to our Dispatch data. We have placenames tagged — and we already have the data ready for processing. We can focus on a specific period of time (by filtering our data, including only dates that we are interested in). Then we need to calculate frequencies of mentions of placenames — we can use these values to size dots on the final map. Unfortunately, a very important element is missing — as you recall, our data does not have any coordinates. Luckily, we have unique identifiers from the Getty Thesaurus of Geographical Names. What we can do is to extract coordinates from the Thesaurus and connect them to corresponding placenames in our data. Getty Thesaurus is available for download here: http://tgndownloads.getty.edu/ and here: http://vocab.getty.edu/dataset/tgn/ You can download explicit.zip from http://vocab.getty.edu/dataset/tgn/ There is a file TGNOut_Coordinates.nt with coordinates. You will need to write a script to extract coordinates from this file in order to use them. I suggest you convert this file (the format is N-triples) 11.1.1 Triples (N-triples) What are triples? This is one of the most robust formats that can describe any kind of data. The main idea is that every triple is expressed through the structure subject-predicate-object. There are multiple formats for expressing triples (for example, RDF, N-Triples, etc.) (more details…). Let’s take a look at the following example from TGNOut_Coordinates.nt. There are three triples (N-triples) which together describe a specific object (which in our data would look like tgn,1000007). &lt;http://vocab.getty.edu/tgn/1000007-geometry&gt; &lt;http://www.w3.org/1999/02/22-rdf-syntax-ns#type&gt; &lt;http://schema.org/GeoCoordinates&gt; . &lt;http://vocab.getty.edu/tgn/1000007-geometry&gt; &lt;http://schema.org/latitude&gt; &quot;-83.843&quot;^^&lt;http://www.w3.org/2001/XMLSchema#decimal&gt; . &lt;http://vocab.getty.edu/tgn/1000007-geometry&gt; &lt;http://schema.org/longitude&gt; &quot;65.725&quot;^^&lt;http://www.w3.org/2001/XMLSchema#decimal&gt; . Each triple is stored on a separate line, ending with a period (“.”). Elements of each triple are separated with spaces. Each triple has the same structure—subject-predicate-object—and can be read as follows. Triple 1: entity tgn,1000007 has (expressed in a particular manner) geographical coordinates; Triple 2: entity tgn,1000007 has decimal latitude -83.843; Triple 3: entity tgn,1000007 has decimal longitude 65.725; You should have no problems writing a script that converts this data into a CSV with the structure: ID, lon, and lat. (Technically, you can also store these triples in a CSV/TSV format, but that would require additional conversion later.) If you are not up to this challenge, you can use the CSV file that I have already prepared, to make your life a bit easier: TGNOut_Coordinates.csv.zip If everything done correctly, the map may look like this (although an interactive temporary component is an extra): Here is the link to the description of how dynamic maps can be done: Bubble Map with Animation. Use this example to produce something similar for the Dispatch data. Last but not least, we may get interesting maps if we map places that cooccur with some specific names. An example of Gen. Sherman and Atlanta could be quite interesting (we have seen the graphs in the previous lesson), although in such cases a chronological graph of mentions of Altanta—only in articles where Gen. Sherman is mentioned—may be a more clear option. Please, try to code a solution that will do one or the other :) 11.2 Homework Graph geographical data from the Dispatch. Experiment with different periods and different selections of placenames (for example, Richmond and Virginia will be the most frequently mentioned placenames—because the newspaper was published in Richmond, Virginia; this would mean that these two places will overshadow all other places.) Suggestions: you can create a separate data file that only has placenames (articleID, date, placename, lat, lon) you can map places in a more complex manner. For example, map only placenames that are mentioned in the same articles as, say, General Sherman. In this case we may expect the maps to reflect his campaign through Georgia and the Carolinas (or, more precisely, the Dispatch’s coverage of Gen. Sherman’s campaign). for interactive maps, you can use Plotly library: https://plotly.com/python/bubble-maps/. Finish the assigned task; Annotate your script (i.e., add comment to every line of code describing what is happenning there); Additional materials: Interactive maps with Plotly: https://plotly.com/python/bubble-maps/; Basemap Matplotlib Toolkit: Plotting data on a map (Example Gallery). Python Data Science Handbook by Jake VanderPlas Chapter 4. Visualization with Matplotlib; Geographic Data with Basemap; How to plot data on maps in Jupyter using Matplotlib, Plotly, and Bokeh; Visualization: Mapping Global Earthquake Activity. Submitting homework: Homework assignment must be submitted by the beginning of the next class; Now, that you know how to use GitHub, you will be submitting your homework pushing it to github: Create a relevant subfolder in your repository and place your HW files there; push them to your GitHub account; Email me the link to your repository with a short message (Something like: I have completed homework for Lesson 3, which is uploaded to my repository … in subfolder L03) 11.3 Solution Below is the solution to the homework… "],["lesson-12-topic-modeling-tf-idf-automatic-text-analysis.html", "12 Lesson 12: Topic Modeling &amp; TF-IDF (automatic text analysis) 12.1 Goals: 12.2 Software 12.3 Workbooks (jupyter notebooks) 12.4 Installing: on Windows 12.5 Installing: on Mac and Linux 12.6 python libraries and additional data 12.7 jupyter notebook 12.8 installing from a jupyter notebook 12.9 Files &amp; Scripts 12.10 Thinking about themes and topics 12.11 Topic Modeling 12.12 Implementation 12.13 TF-IDF 12.14 Homework 12.15 Solution", " 12 Lesson 12: Topic Modeling &amp; TF-IDF (automatic text analysis) 12.1 Goals: Introduction to topic modeling, or how to classify texts by shared content (“topics”). 12.2 Software python jupyter notebook other python libraries wheel (this package is helpful for the installation of gensim and pyLDAvis) nltk gensim spacy pyLDAvis matplotlib numpy pandas plotly pprint 12.3 Workbooks (jupyter notebooks) for Windows for Mac and Linux 12.4 Installing: on Windows On Mac and Linux things are easy, just follow the commands below; for Windows things are trickier and the easiest way would be to use Anaconda https://www.anaconda.com/distribution/#download-section. Please, download and install. Most packages will come with Anaconda distribution; others you can install through its interface. NB: After Anaconda is installed, it is still better to install libraries from the terminal opened directly from Anaconda and using the following command conda install -c conda-forge gensim (the latest version is not available via Anaconda interface). More details: https://radimrehurek.com/gensim/install.html 12.5 Installing: on Mac and Linux 12.6 python libraries and additional data pip install nameOfLibrary Lemmatization library (although we are not going to be using it in the tutorial) python -m spacy download en 12.7 jupyter notebook From command line (in your working folder) # installing pip install jupyter # starting jupyter notebook 12.8 installing from a jupyter notebook The required libraries can also be installed directly from your Jupyter notebook as shown below—note ! in front of pip. (Note: You might need to use pip3 instead of pip, depending on your overall python setup) # installing !pip install nltk !pip install gensim !pip install spacy !pip install pyLDAvis Your default browser should open something like this: Click on an *.ipynb file to open a notebook. 12.9 Files &amp; Scripts Dispatch CSV files Jupyter notebook 12.10 Thinking about themes and topics Let’s take a look at the following three examples and think about what themes and topics they cover. More importantly, let’s think about how we “assign” those themes and topics. What is out thinking process? What textual elements do we keep in mind when we argue that such and such text is about such and such topics? Example 1: Thursday, March 27, 1862 — LIGHT ARTILLERY I am authorized by the Governor of Virginia to raise a Company of Light Artillery for the war. All those desirous of enlisting in this the most effective arm of the service, would do well to call at once at the office of Johnson &amp; Guigon, Whig Building. Uniforms and subsistence furnished. A. B. GUIGON. mh 25—6t Example 2: Wednesday, August 17, 1864 — Royal Marriages. There is a story circulated in Germany, and some in Paris, that the match between the heir-apparent of the Imperial throne of Russia and the Princess Dagmar of Denmark having been definitively broken off, another is in the course of negotiation between His Imperial Highness and the Princess Helens of England. Example 3: Monday, June 22, 1863 — NEWS FROM EUROPE. The steamship Scotia arrived at New York on Thursday from Europe, with foreign news to the 7th inst. The news is not important. The Confederate steamer Lord Clyde was searched by order of the British Government, but nothing contraband being found on board her she was permitted to sail. The Russians have been defeated near Grochoury by the Polish insurgents. The three Powers have sent an earnest note to Russia, asking for a representative Government, a general amnesty, and an immediate cessation of hostilities in Poland. 12.11 Topic Modeling The formal definition of topic modeling is “…” (Source: …) 12.12 Implementation 1. Preparing Data. First, we need to make sure to convert the Dispatch into a suitable format. As I stressed before, TSV/CSV tabular format is one of the most universal. Let’s go back to our reformatting script and change it in such a way that it collects data in the TSV format (TSV will help us to avoid the issue with commas in the CSV format) and aggregates all articles published in the same year in one file. You can think of writing a function that takes three arguments: a path to the folder with downloaded initial XML files; a path to the folder where you want to save the results; and the year value. You will need to add some lines of code that test if each specific newspaper issue has been published in a particular year (your third argument): if yes, you collect it; else, you skip it. This script will allow us to aggregate quite a significant amount if text into more manageable chunks (it will give us 5 files instead of 1300+). The solution script will be added to the end of this lesson later. 2. Necessary Libraries …. … 3. Loading Data … … 4. Preprocessing Data … … 5. Training a Model … ** 12.13 TF-IDF TF-IDF is the most common automatic method for identifying keywords in texts. This method is the standard approach for identifying keywords. It was first proposed almost fifty years ago by Spärck Jones (1972); Ramsay (2011), in Chapter 1, offers a detailed humanistic explanation of this approach. This approach is statistical in its nature and therefore requires a sizable collection of texts for meaningful results. In the case of small collections you are likely to observe that the selection of keywords for the same text change significantly with every new addition to the collection of texts. This is because the method takes into account frequencies of each word and the number of documents in which this word occurs. For example, if your collection includes 10 articles that discuss different aspects of the ʿAbbāsid caliphate, with some focused on politics, some on economics, and some on culture, the word “ʿAbbāsid” will most likely not be included into the list of suggested keywords (since all articles have this term), but words like “politics”, “economics”, and “culture” will be in this list, since they appear only in some articles. If you add ten other articles to your collection—and these will deal, say, with the Ottomans—then the word “ʿAbbāsid” will crawl up in the list of keywords for articles dealing with the ʿAbbasids. In other words, if your collection includes texts on the same broad topic (say, the ʿAbbāsids), the TF-IDF algorithm will assign high keywordness to those terms that point to narrower subjects within the broader subject of the ʿAbbāsids. In cases when one has to run the topic modeling algorithm on a very large collection of texts, TF-IDF can be used in order to reduce the size of the corpus. That is to say, the corpus is first reduced to the TF-IDF abstractions and then the topic modeling algorithm is applied to these abstractions rather than to the complete initial texts. TF-IDF abstractions can also be used to identify texts on similar topics across a large corpus of texts. In this approach one would calculate the distance between the vectors of TF-IDF abstractions. This approach mathematically checks whether to what extent two different documents share keywords and to what extent the numeric values of these keywords are similar: the more keywords they share and the more similar the keyword values are, the more similar the texts will be. (More details….) 12.14 Homework Finish the assigned task; Annotate your script (i.e., add comment to every line of code describing what is happenning there); Submitting homework: Homework assignment must be submitted by the beginning of the next class; Now, that you know how to use GitHub, you will be submitting your homework pushing it to github: Create a relevant subfolder in your repository and place your HW files there; push them to your GitHub account; Email me the link to your repository with a short message (Something like: I have completed homework for Lesson 3, which is uploaded to my repository … in subfolder L03) 12.15 Solution The solutions will be added soon… # REFORMATTING THE DISPATCH INTO TSV FILES import re import os source = &quot;./Dispatch/&quot; target = &quot;./Dispatch_Processed_TSV/&quot; # needs to be created beforehand! def convertDispatchToCSV(source, target, YEAR): print(&quot;Collecting data for year: %s&quot; % YEAR) issueVar = [] lof = os.listdir(source) for f in lof: if f.startswith(&quot;dltext&quot;): # fileName test c = 0 # technical counter with open(source + f, &quot;r&quot;, encoding=&quot;utf8&quot;) as f1: text = f1.read() date = re.search(r&#39;&lt;date value=&quot;([\\d-]+)&quot;&#39;, text).group(1) if date[:4] == str(YEAR): split = re.split(&quot;&lt;div3 &quot;, text) for s in split[1:]: s = &quot;&lt;div3 &quot; + s # a step to restore the integrity of items try: unitType = re.search(r&#39;type=&quot;([^\\&quot;]+)&quot;&#39;, s).group(1) except: unitType = &quot;noType&quot; try: header = re.search(r&#39;&lt;head.*&lt;/head&gt;&#39;, s).group(0) header = re.sub(&quot;&lt;[^&lt;]+&gt;&quot;, &quot;&quot;, header) except: header = &quot;NO HEADER&quot; text = s text = re.sub(&quot;&lt;[^&lt;]+&gt;&quot;, &quot; &quot;, text) text = re.sub(&quot; +\\n|\\n +&quot;, &quot;\\n&quot;, text) text = text.strip() text = re.sub(&quot;\\n+&quot;, &quot;;;; &quot;, text) text = re.sub(&quot; +&quot;, &quot; &quot;, text) text = re.sub(r&quot; ([\\.,:;!])&quot;, r&quot;\\1&quot;, text) itemID = date + &quot;_&quot; + unitType + &quot;_%03d&quot; % c if len(re.sub(&quot;\\W+&quot;, &quot;&quot;, text)) != 0: var = &quot;\\t&quot;.join([itemID, date, unitType, header, text]) issueVar.append(var) print(&quot;\\tcollected: %d items&quot; % len(issueVar)) issueNew = &quot;\\n&quot;.join(issueVar) header = &quot;\\t&quot;.join([&quot;id&quot;, &quot;date&quot;, &quot;type&quot;, &quot;header&quot;, &quot;text&quot;]) with open(target + &quot;Dispatch_%s.tsv&quot; % str(YEAR), &quot;w&quot;, encoding=&quot;utf8&quot;) as f9: f9.write(header + &quot;\\n&quot; + issueNew) convertDispatchToCSV(source, target, 1860) convertDispatchToCSV(source, target, 1861) convertDispatchToCSV(source, target, 1862) convertDispatchToCSV(source, target, 1863) convertDispatchToCSV(source, target, 1864) convertDispatchToCSV(source, target, 1865) References "],["lesson-13-social-network-analysis.html", "13 Lesson 13: Social Network Analysis 13.1 … 13.2 Homework 13.3 Solution", " 13 Lesson 13: Social Network Analysis 13.1 … … 13.2 Homework Finish the assigned task; Annotate your script (i.e., add comment to every line of code describing what is happenning there); Submitting homework: Homework assignment must be submitted by the beginning of the next class; Now, that you know how to use GitHub, you will be submitting your homework pushing it to github: Create a relevant subfolder in your repository and place your HW files there; push them to your GitHub account; Email me the link to your repository with a short message (Something like: I have completed homework for Lesson 3, which is uploaded to my repository … in subfolder L03) 13.3 Solution Below is the solution to the homework… "],["appendix.html", "Appendix", " Appendix Article 01 Article 02 Article 03 Article 04 Article 05 Article 06 Article 07 Article 08 Article 09 Article 10 Article 11 Article 12 Article 13 Article 14 Article 15 "],["references.html", "References", " References "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
